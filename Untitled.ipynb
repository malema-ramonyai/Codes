{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-022d2311920a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLightCurveDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_mag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_mag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \"\"\"\n\u001b[1;32m      4\u001b[0m         \u001b[0mReads\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlight\u001b[0m \u001b[0mcurve\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class LightCurveDataset(Dataset):\n",
    "    def __init__(self, lower_mag=1, upper_mag=25, **kwargs):\n",
    "        \"\"\"\n",
    "        Reads in light curve data from file(s).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            If a single file (of any time) is to be read from, the path can be\n",
    "            given using this kwarg. \n",
    "        directory : str\n",
    "            A directory can be given instead of an explicit list of files. The\n",
    "            child class will load all appropriate files in this directory.\n",
    "        list_of_files : list\n",
    "            Instead of the above, a list of files to be loaded can be\n",
    "            explicitly given.\n",
    "        output_dir : str\n",
    "            The directory to save the log file and all outputs to. Defaults to\n",
    "            './' \n",
    "        lower_mag : float, optional\n",
    "            Applies a cut to the data, excludes everything above this, by \n",
    "            default 1\n",
    "        upper_mag : int, optional\n",
    "            Applies a cut to the data, excludes everything below this, by \n",
    "            default 25\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(lower_mag=lower_mag, upper_mag=upper_mag, **kwargs)\n",
    "\n",
    "        self.data_type = 'light_curve'\n",
    "\n",
    "        self.metadata = pd.DataFrame(data=[])\n",
    "\n",
    "        ids = [f.split(os.sep)[-1] for f in self.files]\n",
    "        self.metadata = pd.DataFrame({'filepath': self.files}, index=ids)\n",
    "\n",
    "        self.lower_mag = lower_mag\n",
    "        self.upper_mag = upper_mag\n",
    "\n",
    "    @staticmethod\n",
    "    def read_lc_from_file(flpath):\n",
    "        \"\"\"\n",
    "        Reads the light curve from file returning a dataframe\n",
    "        \"\"\"\n",
    "        light_curve = pd.read_csv(flpath, delim_whitespace=True)\n",
    "        return light_curve\n",
    "\n",
    "    def get_display_data(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single instance of the dataset in a form that is ready to be\n",
    "        displayed by the web front end.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : str\n",
    "            Index (should be a string to avoid ambiguity)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            json-compatible dictionary of the light curve data\n",
    "        \"\"\"\n",
    "        # print(id)\n",
    "        # ***** Need to extend this to deal with other bands\n",
    "        time_col = 'time'\n",
    "        mag_col = 'mag'\n",
    "        err_col = 'mag_err'\n",
    "\n",
    "        out_dict = {}\n",
    "\n",
    "        metadata = self.metadata\n",
    "        flpath = metadata[idx]['filepath'].iloc[0]\n",
    "        \n",
    "    \n",
    "        try:\n",
    "            \n",
    "#             light_curve = self.read_lc_from_file(flpath)\n",
    "#             light_curve = light_curve[\n",
    "#                 (self.lower_mag < light_curve[mag_col]) & \n",
    "#                 (light_curve[mag_col] < self.upper_mag)]\n",
    "#             light_curve['err_lower'] = light_curve[mag_col] - \\\n",
    "#                 light_curve[err_col]\n",
    "#             light_curve['err_upper'] = light_curve[mag_col] + \\\n",
    "#                 light_curve[err_col]\n",
    "\n",
    "            out_dict['data'] = light_curve[[time_col, mag_col]].values.tolist()\n",
    "            lc_errs = light_curve[[time_col, 'err_lower', 'err_upper']]\n",
    "            out_dict['errors'] = lc_errs.values.tolist()\n",
    "\n",
    "        except (pd.errors.ParserError, pd.errors.EmptyDataError, \n",
    "                FileNotFoundError) as e:\n",
    "            print('Error parsing file', flpath)\n",
    "            print('Error message:')\n",
    "            print(e)\n",
    "            out_dict = {'data': [], 'errors': []}\n",
    "\n",
    "        return out_dict\n",
    "    \n",
    "    \n",
    "    def get_sample(self, idx):\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        Returns the data for a single sample in the dataset as indexed by idx.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : string\n",
    "            Index of sample\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        nd.array\n",
    "            Array of image cutout\n",
    "            \n",
    "        \n",
    "        Function must return a data in a format that the feature extractor expects\n",
    "        \"\"\"\n",
    "         \n",
    "        \n",
    "\n",
    "        \n",
    "        return cutout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dt = pd.DataFrame(data=[])\n",
    "\n",
    "dt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['malema', 'ramonyai', 'kb']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files = ['malema','ramonyai','kb']\n",
    "\n",
    "ids = [f.split(os.sep)[-1] for f in files]\n",
    "\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
