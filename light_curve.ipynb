{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feets.preprocess\n",
    "from scipy import stats\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import feets\n",
    "from ipykernel import kernelapp as app\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "script_dir = os.path.dirname('Results/')\n",
    "results_dir = os.path.join(script_dir, 'Images/')\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "    \n",
    "# Plastic_data = pd.read_csv('test_set_batch1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/MachineLearningUniandes/MANTRA/master/data/lightcurves/transient_lightcurves.csv\"\n",
    "url1 = 'https://raw.githubusercontent.com/MachineLearningUniandes/MANTRA/master/data/lightcurves/transient_labels.csv'\n",
    "url2 = 'https://raw.githubusercontent.com/MachineLearningUniandes/MANTRA/master/data/lightcurves/transient_info.txt'\n",
    "# transient_lc = pd.read_csv(url)\n",
    "# transient_labels = pd.read_csv(url1)\n",
    "# transient_info = pd.read_table(url2,skiprows=1,names=['CRTS_ID' ,'RA' ,'Dec','UT_Date','Mag','CSS_images' ,'SDSS',\n",
    "#                                                       'Others' ,'Followed' ,'Last','LC','FC','Classification'])\n",
    "\n",
    "# transient_lc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lc_from_file(flpath,lc_columns,fl_columns,header_nrows):\n",
    "\n",
    "\n",
    "        # Possible file extensions\n",
    "        extn = ['.csv','.dat','.txt']\n",
    "\n",
    "        for ext in extn:\n",
    "\n",
    "            \n",
    "            # ==========CSV_files=============\n",
    "            if ext in flpath and ext == extn[0]:\n",
    "\n",
    "                # Reading in the data\n",
    "                light_curve=pd.read_csv(flpath,skiprows=header_nrows,names=fl_columns)\n",
    "                # Selecting columns with lc data\n",
    "                light_curve = light_curve.loc[:,lc_columns]            \n",
    "                # Renaming the columns into standard names for astronomaly\n",
    "                light_curve.columns = ['time','mag','magerr']\n",
    "                \n",
    "                return light_curve\n",
    "\n",
    "            # ==========.Dat_file=============\n",
    "            else:\n",
    "                \n",
    "                # Reading in the data\n",
    "                light_curve = pd.read_table(flpath,skiprows=header_nrows,names=fl_columns,delim_whitespace=True)\n",
    "                # Selecting columns with lc data\n",
    "                light_curve = light_curve.loc[:,lc_columns]\n",
    "                # Renaming the columns into standard names for astronomaly\n",
    "                light_curve.columns = ['time','mag1','mag2']\n",
    "                \n",
    "                return light_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lc1(flpath,data_dict):\n",
    "    \n",
    "    '''Function to read the lc from the data\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    flpath: the location of the file\n",
    "    \n",
    "    data_dict: dictionary with the keys ('time','mag','magerr')\n",
    "               the user provides the values corresponding to the keys\n",
    "               e.g {'time':'mjd'}, were 'mjd' is the time column name in the \n",
    "               data\n",
    "               \n",
    "   Output:\n",
    "   \n",
    "   standardized pandas dataframe with lc data'''\n",
    "    \n",
    "    \n",
    "    # Reading-in the data\n",
    "    data = pd.read_csv(flpath)\n",
    "        \n",
    "    \n",
    "    # This for column names \n",
    "    if type(data_dict['time']) == str:\n",
    "    \n",
    "        # Separatting the columns as per input dictionary\n",
    "        time = data.loc[:,data_dict['time']]; \n",
    "        mag = data.loc[:,data_dict['mag']]; \n",
    "        error = data.loc[:,data_dict['mag_errors']]\n",
    "        \n",
    "    \n",
    "    # This is for column indx\n",
    "    else:\n",
    "        \n",
    "        # Separatting the columns as per input dictionary\n",
    "        time = data.iloc[:,data_dict['time']]; \n",
    "        mag = data.iloc[:,data_dict['mag']]; \n",
    "        error = data.iloc[:,data_dict['mag_errors']]\n",
    "    \n",
    "    # Creating a new dictionary for the columns above separate data\n",
    "    new_data = {'time':time,'mag':mag,'error':error}\n",
    "    \n",
    "    \n",
    "    \n",
    "    return pd.DataFrame.from_dict(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd attempt of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think the best is to use the column indexs\n",
    "def read_lc2(flpath,data_dict):\n",
    "    \n",
    "    '''Function to read the lc from the data\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    flpath: the location of the file\n",
    "    \n",
    "    data_dict: dictionary with the keys ('time','mag','mag_err','flux','flux_err','filters')\n",
    "               the user provides the values corresponding to the keys\n",
    "               e.g {'time':1}, were 1 is the time column index\n",
    "               \n",
    "    brightness_unit: Units used to measure the brightness\n",
    "                     can either be 'flux' or 'mags'\n",
    "               \n",
    "   Output:\n",
    "   \n",
    "   standardized pandas dataframe with lc data'''\n",
    "    \n",
    "    \n",
    "    # Reading-in the data\n",
    "    data = pd.read_csv(flpath)\n",
    "        \n",
    "    if 'mag' in data_dict.keys(): \n",
    "        \n",
    "        # Separatting the columns as per input dictionary\n",
    "        time = data.iloc[:,data_dict['time']]; \n",
    "        mag = data.iloc[:,data_dict['mag']]; \n",
    "        mag_error = data.iloc[:,data_dict['mag_err']]\n",
    "        # Creating a new dictionary for the columns above separate data\n",
    "        standard_data = {'time':time,'mag':mag,'mag_error':mag_error}\n",
    "        \n",
    "        # Including filters in dataframe\n",
    "        if 'filters' in data_dict.keys():\n",
    "            \n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'time':time,'mag':mag,'mag_error':mag_error,'filters':filters}\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Separatting the columns as per input dictionary\n",
    "        time = data.iloc[:,data_dict['time']]; \n",
    "        flux = data.iloc[:,data_dict['flux']]; \n",
    "        flux_error = data.iloc[:,data_dict['flux_err']]\n",
    "    \n",
    "        standard_data = {'time':time,'flux':flux,'flux_error':flux_error}\n",
    "        \n",
    "        # Including filters in the dataframe\n",
    "        if 'filters' in data_dict.keys():\n",
    "            \n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'time':time,'flux':flux,'flux_error':flux_error,'filters':filters}\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    return pd.DataFrame.from_dict(standard_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/malema/Desktop/Malema_UWC_Work/Data/test_set_batch1.csv'\n",
    "\n",
    "# read_lc2(flpath=path,data_dict={'time':0,'mag':1,'mag_err':2})\n",
    "\n",
    "dt=pd.read_csv(path,skiprows=1,header=None,delim_whitespace=False)\n",
    "# dt.iloc[:,[1,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fouth Attempt\n",
    "\n",
    "#### The fourth attempt will aim to make changes to the read_lc\n",
    "#### Such that it can read a lc with multiple mag columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think the best is to use the column indexs\n",
    "def read_lc3(flpath,data_dict,header_nrows,delim_whitespace):\n",
    "    \n",
    "    '''Function to read the lc from the data\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    flpath: the location of the file\n",
    "    \n",
    "    data_dict: dictionary with the keys ('time','mag','mag_err','flux','flux_err','filters')\n",
    "               the user provides the values corresponding to the keys\n",
    "               e.g {'time':1}, were 1 is the time column index\n",
    "               \n",
    "    brightness_unit: Units used to measure the brightness\n",
    "                     can either be 'flux' or 'mags'\n",
    "                     \n",
    "    header_nrows: The number of rows the header covers\n",
    "    \n",
    "    delim_whitespace: True when the data is not separated by a comma, false otherwise\n",
    "               \n",
    "   Output:\n",
    "   \n",
    "   standardized pandas dataframe with lc data'''\n",
    "    \n",
    "    \n",
    "    # Reading-in the data\n",
    "    data = pd.read_csv(flpath,skiprows=header_nrows,delim_whitespace=delim_whitespace,header=None)\n",
    "        \n",
    "    if 'mag' in data_dict.keys(): \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Separatting the columns as per input dictionary\n",
    "        time = data.iloc[:,data_dict['time']]; \n",
    "        mag = data.iloc[:,data_dict['mag']]; \n",
    "        mag_error = data.iloc[:,data_dict['mag_err']]\n",
    "        # Creating a new dictionary for the columns above separate data\n",
    "        standard_data = {'time':time,'mag':mag,'mag_error':mag_error}\n",
    "        \n",
    "        # Including filters in dataframe\n",
    "        if 'filters' in data_dict.keys():\n",
    "            \n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'time':time,'mag':mag,'mag_error':mag_error,'filters':filters}\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Separatting the columns as per input dictionary\n",
    "        time = data.iloc[:,data_dict['time']]; \n",
    "        flux = data.iloc[:,data_dict['flux']]; \n",
    "        flux_error = data.iloc[:,data_dict['flux_err']]\n",
    "    \n",
    "        standard_data = {'time':time,'flux':flux,'flux_error':flux_error}\n",
    "        \n",
    "        # Including filters in the dataframe\n",
    "        if 'filters' in data_dict.keys():\n",
    "            \n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'time':time,'flux':flux,'flux_error':flux_error,'filters':filters}\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    return pd.DataFrame.from_dict(standard_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/malema/Desktop/Malema_UWC_Work/Data/20121012_02331333_O_CrabNebula_E.dat'\n",
    "\n",
    "dt=read_lc3(flpath=path,data_dict={'time':1,'mag':1,'filters':0,'mag_err':0},delim_whitespace=True,header_nrows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think the best is to use the column indexs\n",
    "def read_lc3(flpath,data_dict,header_nrows,delim_whitespace):\n",
    "    \n",
    "    '''Function to read the lc from the data\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    flpath: the location of the file\n",
    "    \n",
    "    data_dict: dictionary with the keys ('time','mag','mag_err','flux','flux_err','filters')\n",
    "               the user provides the values corresponding to the keys\n",
    "               e.g {'time':1}, were 1 is the time column index\n",
    "               \n",
    "    brightness_unit: Units used to measure the brightness\n",
    "                     can either be 'flux' or 'mags'\n",
    "                     \n",
    "    header_nrows: The number of rows the header covers\n",
    "    \n",
    "    delim_whitespace: True when the data is not separated by a comma, false otherwise\n",
    "               \n",
    "   Output:\n",
    "   \n",
    "   standardized pandas dataframe with lc data'''\n",
    "    \n",
    "    \n",
    "    # Reading-in the data\n",
    "    data = pd.read_csv(flpath,skiprows=header_nrows,delim_whitespace=delim_whitespace,header=None)\n",
    "    \n",
    "    \n",
    "    # ==================Magnitudes==================================\n",
    "    # ==============================================================\n",
    "    ID = data.iloc[:,data_dict['id']]\n",
    "    if 'mag' in data_dict.keys(): \n",
    "        \n",
    "        \n",
    "        # ============MUtliple Mag columns=========================\n",
    "        \n",
    "        # The case of multiple brightness columns        \n",
    "        if type(data_dict['mag']) == list:\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; mag1 = data.iloc[:,data_dict['mag'][0]];\n",
    "            mag2 = data.iloc[:,data_dict['mag'][1]]\n",
    "            \n",
    "            # Case where there are brightness error columns\n",
    "            if 'mag_err' in data_dict.keys():                \n",
    "                \n",
    "                mag_error = data.iloc[:,data_dict['mag_err']]\n",
    "                # Creating a new dictionary for the columns above separate data\n",
    "                standard_data = {'ID':ID,'time':time,'mag1':mag1,'mag2':mag2,'mag_error':mag_error}\n",
    "                \n",
    "            # Case were there are no error columns\n",
    "            else:\n",
    "                \n",
    "                standard_data = {'ID':ID,'time':time,'mag1':mag1,'mag2':mag2}\n",
    "                           \n",
    "        \n",
    "        \n",
    "                \n",
    "        # ============Column with Mag_filters and errors==========================\n",
    "        \n",
    "        # Including filters in dataframe\n",
    "        elif 'filters'in data_dict.keys() and 'mag_err' in data_dict.keys():\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; mag = data.iloc[:,data_dict['mag']];\n",
    "            mag_error = data.iloc[:,data_dict['mag_err']]\n",
    "\n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'ID':ID,'time':time,'mag':mag,'mag_error':mag_error,'filters':filters}\n",
    "            \n",
    "        elif 'filters' in data_dict.keys():\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; mag = data.iloc[:,data_dict['mag']];\n",
    "    \n",
    "\n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'ID':ID,'time':time,'mag':mag,'filters':filters}\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        #=================Single Mag Column with and with errors============================\n",
    "        \n",
    "        # Case of single brightness columns    \n",
    "        else:    \n",
    "            \n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; mag = data.iloc[:,data_dict['mag']]; \n",
    "            \n",
    "            if 'mag_err' in data_dict.keys():\n",
    "                \n",
    "                \n",
    "                mag_error = data.iloc[:,data_dict['mag_err']]\n",
    "                # Creating a new dictionary for the columns above separate data\n",
    "                standard_data = {'ID':ID,'time':time,'mag':mag,'mag_error':mag_error}\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                standard_data = {'ID':ID,'time':time,'mag':mag}\n",
    "                \n",
    "                \n",
    "#-----------------------------------------------------------------------------------------------------------------                \n",
    "            \n",
    "#`````````````````````````````````````````````````````````````````````````````````````````````````````````````````      \n",
    "#============================================Fluxes===============================================================\n",
    "#=================================================================================================================\n",
    "#`````````````````````````````````````````````````````````````````````````````````````````````````````````````````\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        \n",
    "        \n",
    "                # ============MUtliple Mag columns=========================\n",
    "        \n",
    "        # The case of multiple brightness columns        \n",
    "        if type(data_dict['flux']) == list:\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; flux1 = data.iloc[:,data_dict['flux'][0]];\n",
    "            flux2 = data.iloc[:,data_dict['flux'][1]]\n",
    "            \n",
    "            # Case where there are brightness error columns\n",
    "            if 'flux_err' in data_dict.keys():                \n",
    "                \n",
    "                flux_error = data.iloc[:,data_dict['flux_err']]\n",
    "                # Creating a new dictionary for the columns above separate data\n",
    "                standard_data = {'ID':ID,'time':time,'flux1':flux1,'flux2':flux2,'flux_error':flux_error}\n",
    "                \n",
    "            # Case were there are no error columns\n",
    "            else:\n",
    "                \n",
    "                standard_data = {'ID':ID,'time':time,'flux1':flux1,'flux2':flux2}\n",
    "                           \n",
    "        \n",
    "        \n",
    "                \n",
    "        # ============Column with Mag_filters and errors==========================\n",
    "        \n",
    "        # Including filters in dataframe\n",
    "        elif 'filters'in data_dict.keys() and 'flux_err' in data_dict.keys():\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; flux = data.iloc[:,data_dict['flux']];\n",
    "            flux_error = data.iloc[:,data_dict['flux_err']]\n",
    "\n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'ID':ID,'time':time,'flux':flux,'flux_error':flux_error,'filters':filters}\n",
    "            \n",
    "        elif 'filters' in data_dict.keys():\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; flux = data.iloc[:,data_dict['flux']];\n",
    "    \n",
    "\n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'ID':ID,'time':time,'flux':flux,'filters':filters}\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        #=================Single Mag Column with and with errors============================\n",
    "        \n",
    "        # Case of single brightness columns    \n",
    "        else:    \n",
    "            \n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; flux = data.iloc[:,data_dict['flux']]; \n",
    "            \n",
    "            if 'flux_err' in data_dict.keys():\n",
    "                \n",
    "                \n",
    "                flux_error = data.iloc[:,data_dict['flux_err']]\n",
    "                # Creating a new dictionary for the columns above separate data\n",
    "                standard_data = {'ID':ID,'time':time,'flux':flux,'flux_error':flux_error}\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                standard_data = {'ID':ID,'time':time,'flux':flux}\n",
    "        \n",
    "        \n",
    "        \n",
    "#         # Separatting the columns as per input dictionary\n",
    "#         ID = data.iloc[:,data_dict['id']]; time = data.iloc[:,data_dict['time']]; \n",
    "#         flux = data.iloc[:,data_dict['flux']]; flux_error = data.iloc[:,data_dict['flux_err']];\n",
    "    \n",
    "#         standard_data = {'ID':ID,'time':time,'flux':flux,'flux_error':flux_error}\n",
    "        \n",
    "#         # Including filters in the dataframe\n",
    "#         if 'filters' in data_dict.keys():\n",
    "            \n",
    "#             filters = data.iloc[:,data_dict['filters']]\n",
    "#             standard_data = {'ID':ID,'time':time,'flux':flux,'flux_error':flux_error,'filters':filters}\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    return pd.DataFrame.from_dict(standard_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the data in all three files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = '/home/malema/Desktop/Malema_UWC_Work/Data/20121012_02331333_O_CrabNebula_E.dat' # Oseti\n",
    "path2 = '/home/malema/Desktop/Malema_UWC_Work/Data/test_set_batch1.csv'  # Plastic\n",
    "path3 = url  # CRTS\n",
    "\n",
    "oSETI_dt=read_lc3(flpath=path1,data_dict={'time':1,'flux':[2,3],'id':5},delim_whitespace=True,header_nrows=2)\n",
    "\n",
    "plasticc_dt=read_lc3(flpath=path2,data_dict={'time':1,'flux':3,'flux_err':4,'id':0,'filters':2},\n",
    "                     delim_whitespace=False,header_nrows=1)\n",
    "\n",
    "CRTS_dt=read_lc3(flpath=path3,data_dict={'time':4,'mag':2,'mag_err':3,'id':0},\n",
    "                     delim_whitespace=False,header_nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing their headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRTS \n",
      "                           ID          time      mag  mag_error\n",
      "0  TranID1409030010044114444  53766.089871  18.8765   0.166417\n",
      "1  TranID1409030010044114444  53990.458866  20.0519   0.281733\n",
      "2  TranID1409030010044114444  53996.286004  20.2199   0.295764\n",
      "3  TranID1409030010044114444  54385.205789  21.1192   0.495390\n",
      "4  TranID1409030010044114444  54355.282285  19.3289   0.195002 \n",
      "\n",
      "oSETI \n",
      "      ID      time     flux1     flux2\n",
      "0  8607  0.106574  0.000082 -0.102021\n",
      "1  8608  0.106574  0.000017 -0.108044\n",
      "2  8609  0.106574  0.000017 -0.094419\n",
      "3  8610  0.106574  0.000050 -0.101473\n",
      "4  8611  0.106574  0.000050 -0.103084 \n",
      "\n",
      "Plastc \n",
      "    ID        time      flux  flux_error  filters\n",
      "0  13  59798.3205 -1.299735    1.357315        2\n",
      "1  13  59798.3281 -2.095392    1.148654        1\n",
      "2  13  59798.3357 -0.923794    1.763655        3\n",
      "3  13  59798.3466 -4.009815    2.602911        4\n",
      "4  13  59798.3576 -3.403503    5.367328        5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('CRTS \\n',CRTS_dt.head(),'\\n')\n",
    "\n",
    "print('oSETI \\n',oSETI_dt.head(),'\\n')\n",
    "print('Plastc \\n',plasticc_dt.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRTS_dt['jst'] = np.linspace(1,100,len(CRTS_dt.ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>time</th>\n",
       "      <th>mag</th>\n",
       "      <th>mag_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TranID1409030010044114444</td>\n",
       "      <td>53766.089871</td>\n",
       "      <td>18.8765</td>\n",
       "      <td>0.166417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TranID1409030010044114444</td>\n",
       "      <td>53990.458866</td>\n",
       "      <td>20.0519</td>\n",
       "      <td>0.281733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TranID1409030010044114444</td>\n",
       "      <td>53996.286004</td>\n",
       "      <td>20.2199</td>\n",
       "      <td>0.295764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TranID1409030010044114444</td>\n",
       "      <td>54385.205789</td>\n",
       "      <td>21.1192</td>\n",
       "      <td>0.495390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TranID1409030010044114444</td>\n",
       "      <td>54355.282285</td>\n",
       "      <td>19.3289</td>\n",
       "      <td>0.195002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440464</th>\n",
       "      <td>TranID1209190181234125108</td>\n",
       "      <td>56189.314816</td>\n",
       "      <td>18.1952</td>\n",
       "      <td>0.123607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440465</th>\n",
       "      <td>TranID1209190181234125108</td>\n",
       "      <td>56189.322996</td>\n",
       "      <td>18.2097</td>\n",
       "      <td>0.124706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440466</th>\n",
       "      <td>TranID1209190181234125108</td>\n",
       "      <td>56205.285887</td>\n",
       "      <td>18.5116</td>\n",
       "      <td>0.138816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440467</th>\n",
       "      <td>TranID1209190181234125108</td>\n",
       "      <td>56205.292631</td>\n",
       "      <td>18.3150</td>\n",
       "      <td>0.128915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440468</th>\n",
       "      <td>TranID1209190181234125108</td>\n",
       "      <td>56218.237507</td>\n",
       "      <td>18.6342</td>\n",
       "      <td>0.152335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440469 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ID          time      mag  mag_error\n",
       "0       TranID1409030010044114444  53766.089871  18.8765   0.166417\n",
       "1       TranID1409030010044114444  53990.458866  20.0519   0.281733\n",
       "2       TranID1409030010044114444  53996.286004  20.2199   0.295764\n",
       "3       TranID1409030010044114444  54385.205789  21.1192   0.495390\n",
       "4       TranID1409030010044114444  54355.282285  19.3289   0.195002\n",
       "...                           ...           ...      ...        ...\n",
       "440464  TranID1209190181234125108  56189.314816  18.1952   0.123607\n",
       "440465  TranID1209190181234125108  56189.322996  18.2097   0.124706\n",
       "440466  TranID1209190181234125108  56205.285887  18.5116   0.138816\n",
       "440467  TranID1209190181234125108  56205.292631  18.3150   0.128915\n",
       "440468  TranID1209190181234125108  56218.237507  18.6342   0.152335\n",
       "\n",
       "[440469 rows x 4 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CRTS_dt.pop('jst')\n",
    "\n",
    "CRTS_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
