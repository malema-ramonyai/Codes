{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feets.preprocess\n",
    "from scipy import stats\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import feets\n",
    "from ipykernel import kernelapp as app\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "script_dir = os.path.dirname('Results/')\n",
    "results_dir = os.path.join(script_dir, 'Images/')\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "    \n",
    "# Plastic_data = pd.read_csv('test_set_batch1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "IncompleteRead",
     "evalue": "IncompleteRead(1351818 bytes read, 32548608 more expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-e7c5ef2b2d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0murl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://raw.githubusercontent.com/MachineLearningUniandes/MANTRA/master/data/lightcurves/transient_labels.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://raw.githubusercontent.com/MachineLearningUniandes/MANTRA/master/data/lightcurves/transient_info.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtransient_lc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtransient_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m transient_info = pd.read_table(url2,skiprows=1,names=['CRTS_ID' ,'RA' ,'Dec','UT_Date','Mag','CSS_images' ,'SDSS',\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;31m# though mypy handling of conditional imports is difficult.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;31m# See https://github.com/python/mypy/issues/1297\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;31m# Override compression based on Content-Encoding header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(1351818 bytes read, 32548608 more expected)"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/MachineLearningUniandes/MANTRA/master/data/lightcurves/transient_lightcurves.csv\"\n",
    "url1 = 'https://raw.githubusercontent.com/MachineLearningUniandes/MANTRA/master/data/lightcurves/transient_labels.csv'\n",
    "url2 = 'https://raw.githubusercontent.com/MachineLearningUniandes/MANTRA/master/data/lightcurves/transient_info.txt'\n",
    "transient_lc = pd.read_csv(url)\n",
    "transient_labels = pd.read_csv(url1)\n",
    "transient_info = pd.read_table(url2,skiprows=1,names=['CRTS_ID' ,'RA' ,'Dec','UT_Date','Mag','CSS_images' ,'SDSS',\n",
    "                                                      'Others' ,'Followed' ,'Last','LC','FC','Classification'])\n",
    "\n",
    "transient_lc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lc_from_file(flpath,lc_columns,fl_columns,header_nrows):\n",
    "\n",
    "\n",
    "        # Possible file extensions\n",
    "        extn = ['.csv','.dat','.txt']\n",
    "\n",
    "        for ext in extn:\n",
    "\n",
    "            \n",
    "            # ==========CSV_files=============\n",
    "            if ext in flpath and ext == extn[0]:\n",
    "\n",
    "                # Reading in the data\n",
    "                light_curve=pd.read_csv(flpath,skiprows=header_nrows,names=fl_columns)\n",
    "                # Selecting columns with lc data\n",
    "                light_curve = light_curve.loc[:,lc_columns]            \n",
    "                # Renaming the columns into standard names for astronomaly\n",
    "                light_curve.columns = ['time','mag','magerr']\n",
    "                \n",
    "                return light_curve\n",
    "\n",
    "            # ==========.Dat_file=============\n",
    "            else:\n",
    "                \n",
    "                # Reading in the data\n",
    "                light_curve = pd.read_table(flpath,skiprows=header_nrows,names=fl_columns,delim_whitespace=True)\n",
    "                # Selecting columns with lc data\n",
    "                light_curve = light_curve.loc[:,lc_columns]\n",
    "                # Renaming the columns into standard names for astronomaly\n",
    "                light_curve.columns = ['time','mag1','mag2']\n",
    "                \n",
    "                return light_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lc1(flpath,data_dict):\n",
    "    \n",
    "    '''Function to read the lc from the data\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    flpath: the location of the file\n",
    "    \n",
    "    data_dict: dictionary with the keys ('time','mag','magerr')\n",
    "               the user provides the values corresponding to the keys\n",
    "               e.g {'time':'mjd'}, were 'mjd' is the time column name in the \n",
    "               data\n",
    "               \n",
    "   Output:\n",
    "   \n",
    "   standardized pandas dataframe with lc data'''\n",
    "    \n",
    "    \n",
    "    # Reading-in the data\n",
    "    data = pd.read_csv(flpath)\n",
    "        \n",
    "    \n",
    "    # This for column names \n",
    "    if type(data_dict['time']) == str:\n",
    "    \n",
    "        # Separatting the columns as per input dictionary\n",
    "        time = data.loc[:,data_dict['time']]; \n",
    "        mag = data.loc[:,data_dict['mag']]; \n",
    "        error = data.loc[:,data_dict['mag_errors']]\n",
    "        \n",
    "    \n",
    "    # This is for column indx\n",
    "    else:\n",
    "        \n",
    "        # Separatting the columns as per input dictionary\n",
    "        time = data.iloc[:,data_dict['time']]; \n",
    "        mag = data.iloc[:,data_dict['mag']]; \n",
    "        error = data.iloc[:,data_dict['mag_errors']]\n",
    "    \n",
    "    # Creating a new dictionary for the columns above separate data\n",
    "    new_data = {'time':time,'mag':mag,'error':error}\n",
    "    \n",
    "    \n",
    "    \n",
    "    return pd.DataFrame.from_dict(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd attempt of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think the best is to use the column indexs\n",
    "def read_lc2(flpath,data_dict):\n",
    "    \n",
    "    '''Function to read the lc from the data\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    flpath: the location of the file\n",
    "    \n",
    "    data_dict: dictionary with the keys ('time','mag','mag_err','flux','flux_err','filters')\n",
    "               the user provides the values corresponding to the keys\n",
    "               e.g {'time':1}, were 1 is the time column index\n",
    "               \n",
    "    brightness_unit: Units used to measure the brightness\n",
    "                     can either be 'flux' or 'mags'\n",
    "               \n",
    "   Output:\n",
    "   \n",
    "   standardized pandas dataframe with lc data'''\n",
    "    \n",
    "    \n",
    "    # Reading-in the data\n",
    "    data = pd.read_csv(flpath)\n",
    "        \n",
    "    if 'mag' in data_dict.keys(): \n",
    "        \n",
    "        # Separatting the columns as per input dictionary\n",
    "        time = data.iloc[:,data_dict['time']]; \n",
    "        mag = data.iloc[:,data_dict['mag']]; \n",
    "        mag_error = data.iloc[:,data_dict['mag_err']]\n",
    "        # Creating a new dictionary for the columns above separate data\n",
    "        standard_data = {'time':time,'mag':mag,'mag_error':mag_error}\n",
    "        \n",
    "        # Including filters in dataframe\n",
    "        if 'filters' in data_dict.keys():\n",
    "            \n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'time':time,'mag':mag,'mag_error':mag_error,'filters':filters}\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Separatting the columns as per input dictionary\n",
    "        time = data.iloc[:,data_dict['time']]; \n",
    "        flux = data.iloc[:,data_dict['flux']]; \n",
    "        flux_error = data.iloc[:,data_dict['flux_err']]\n",
    "    \n",
    "        standard_data = {'time':time,'flux':flux,'flux_error':flux_error}\n",
    "        \n",
    "        # Including filters in the dataframe\n",
    "        if 'filters' in data_dict.keys():\n",
    "            \n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'time':time,'flux':flux,'flux_error':flux_error,'filters':filters}\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    return pd.DataFrame.from_dict(standard_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59798.3205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59798.3281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59798.3357</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59798.3466</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59798.3576</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855953</th>\n",
       "      <td>60434.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855954</th>\n",
       "      <td>60434.0115</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855955</th>\n",
       "      <td>60434.0224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855956</th>\n",
       "      <td>60435.9857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855957</th>\n",
       "      <td>60436.9840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10855958 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   1  2\n",
       "0         59798.3205  2\n",
       "1         59798.3281  1\n",
       "2         59798.3357  3\n",
       "3         59798.3466  4\n",
       "4         59798.3576  5\n",
       "...              ... ..\n",
       "10855953  60434.0005  3\n",
       "10855954  60434.0115  4\n",
       "10855955  60434.0224  5\n",
       "10855956  60435.9857  0\n",
       "10855957  60436.9840  0\n",
       "\n",
       "[10855958 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/malema/Desktop/Malema_UWC_Work/Data/test_set_batch1.csv'\n",
    "\n",
    "# read_lc2(flpath=path,data_dict={'time':0,'mag':1,'mag_err':2})\n",
    "\n",
    "dt=pd.read_csv(path,skiprows=1,header=None,delim_whitespace=False)\n",
    "dt.iloc[:,[1,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fouth Attempt\n",
    "\n",
    "#### The fourth attempt will aim to make changes to the read_lc\n",
    "#### Such that it can read a lc with multiple mag columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think the best is to use the column indexs\n",
    "def read_lc3(flpath,data_dict,header_nrows,delim_whitespace):\n",
    "    \n",
    "    '''Function to read the lc from the data\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    flpath: the location of the file\n",
    "    \n",
    "    data_dict: dictionary with the keys ('time','mag','mag_err','flux','flux_err','filters')\n",
    "               the user provides the values corresponding to the keys\n",
    "               e.g {'time':1}, were 1 is the time column index\n",
    "               \n",
    "    brightness_unit: Units used to measure the brightness\n",
    "                     can either be 'flux' or 'mags'\n",
    "                     \n",
    "    header_nrows: The number of rows the header covers\n",
    "    \n",
    "    delim_whitespace: True when the data is not separated by a comma, false otherwise\n",
    "               \n",
    "   Output:\n",
    "   \n",
    "   standardized pandas dataframe with lc data'''\n",
    "    \n",
    "    \n",
    "    # Reading-in the data\n",
    "    data = pd.read_csv(flpath,skiprows=header_nrows,delim_whitespace=delim_whitespace,header=None)\n",
    "        \n",
    "    if 'mag' in data_dict.keys(): \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Separatting the columns as per input dictionary\n",
    "        time = data.iloc[:,data_dict['time']]; \n",
    "        mag = data.iloc[:,data_dict['mag']]; \n",
    "        mag_error = data.iloc[:,data_dict['mag_err']]\n",
    "        # Creating a new dictionary for the columns above separate data\n",
    "        standard_data = {'time':time,'mag':mag,'mag_error':mag_error}\n",
    "        \n",
    "        # Including filters in dataframe\n",
    "        if 'filters' in data_dict.keys():\n",
    "            \n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'time':time,'mag':mag,'mag_error':mag_error,'filters':filters}\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Separatting the columns as per input dictionary\n",
    "        time = data.iloc[:,data_dict['time']]; \n",
    "        flux = data.iloc[:,data_dict['flux']]; \n",
    "        flux_error = data.iloc[:,data_dict['flux_err']]\n",
    "    \n",
    "        standard_data = {'time':time,'flux':flux,'flux_error':flux_error}\n",
    "        \n",
    "        # Including filters in the dataframe\n",
    "        if 'filters' in data_dict.keys():\n",
    "            \n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'time':time,'flux':flux,'flux_error':flux_error,'filters':filters}\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    return pd.DataFrame.from_dict(standard_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/malema/Desktop/Malema_UWC_Work/Data/20121012_02331333_O_CrabNebula_E.dat'\n",
    "\n",
    "dt=read_lc3(flpath=path,data_dict={'time':1,'mag':1,'filters':0,'mag_err':0},delim_whitespace=True,header_nrows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dt.time,dt.mag,'.')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think the best is to use the column indexs\n",
    "def read_lc3(flpath,data_dict,header_nrows,delim_whitespace):\n",
    "    \n",
    "    '''Function to read the lc from the data\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    flpath: the location of the file\n",
    "    \n",
    "    data_dict: dictionary with the keys ('time','mag','mag_err','flux','flux_err','filters')\n",
    "               the user provides the values corresponding to the keys\n",
    "               e.g {'time':1}, were 1 is the time column index\n",
    "               \n",
    "    brightness_unit: Units used to measure the brightness\n",
    "                     can either be 'flux' or 'mags'\n",
    "                     \n",
    "    header_nrows: The number of rows the header covers\n",
    "    \n",
    "    delim_whitespace: True when the data is not separated by a comma, false otherwise\n",
    "               \n",
    "   Output:\n",
    "   \n",
    "   standardized pandas dataframe with lc data'''\n",
    "    \n",
    "    \n",
    "    # Reading-in the data\n",
    "    data = pd.read_csv(flpath,skiprows=header_nrows,delim_whitespace=delim_whitespace,header=None)\n",
    "    \n",
    "    \n",
    "    # ==================Magnitudes==================================\n",
    "    # ==============================================================\n",
    "    ID = data.iloc[:,data_dict['id']]\n",
    "    if 'mag' in data_dict.keys(): \n",
    "        \n",
    "        \n",
    "        # ============MUtliple Mag columns=========================\n",
    "        \n",
    "        # The case of multiple brightness columns        \n",
    "        if type(data_dict['mag']) == list:\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; mag1 = data.iloc[:,data_dict['mag'][0]];\n",
    "            mag2 = data.iloc[:,data_dict['mag'][1]]\n",
    "            \n",
    "            # Case where there are brightness error columns\n",
    "            if 'mag_err' in data_dict.keys():                \n",
    "                \n",
    "                mag_error = data.iloc[:,data_dict['mag_err']]\n",
    "                # Creating a new dictionary for the columns above separate data\n",
    "                standard_data = {'ID':ID,'time':time,'mag1':mag1,'mag2':mag2,'mag_error':mag_error}\n",
    "                \n",
    "            # Case were there are no error columns\n",
    "            else:\n",
    "                \n",
    "                standard_data = {'ID':ID,'time':time,'mag1':mag1,'mag2':mag2}\n",
    "                           \n",
    "        \n",
    "        \n",
    "                \n",
    "        # ============Column with Mag_filters and errors==========================\n",
    "        \n",
    "        # Including filters in dataframe\n",
    "        elif 'filters'in data_dict.keys() and 'mag_err' in data_dict.keys():\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; mag = data.iloc[:,data_dict['mag']];\n",
    "            mag_error = data.iloc[:,data_dict['mag_err']]\n",
    "\n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'ID':ID,'time':time,'mag':mag,'mag_error':mag_error,'filters':filters}\n",
    "            \n",
    "        elif 'filters' in data_dict.keys():\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; mag = data.iloc[:,data_dict['mag']];\n",
    "    \n",
    "\n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'ID':ID,'time':time,'mag':mag,'filters':filters}\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        #=================Single Mag Column with and with errors============================\n",
    "        \n",
    "        # Case of single brightness columns    \n",
    "        else:    \n",
    "            \n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; mag = data.iloc[:,data_dict['mag']]; \n",
    "            \n",
    "            if 'mag_err' in data_dict.keys():\n",
    "                \n",
    "                \n",
    "                mag_error = data.iloc[:,data_dict['mag_err']]\n",
    "                # Creating a new dictionary for the columns above separate data\n",
    "                standard_data = {'ID':ID,'time':time,'mag':mag,'mag_error':mag_error}\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                standard_data = {'ID':ID,'time':time,'mag':mag}\n",
    "                \n",
    "                \n",
    "#-----------------------------------------------------------------------------------------------------------------                \n",
    "            \n",
    "#`````````````````````````````````````````````````````````````````````````````````````````````````````````````````      \n",
    "#============================================Fluxes===============================================================\n",
    "#=================================================================================================================\n",
    "#`````````````````````````````````````````````````````````````````````````````````````````````````````````````````\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        \n",
    "        \n",
    "                # ============MUtliple Mag columns=========================\n",
    "        \n",
    "        # The case of multiple brightness columns        \n",
    "        if type(data_dict['flux']) == list:\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; flux1 = data.iloc[:,data_dict['flux'][0]];\n",
    "            flux2 = data.iloc[:,data_dict['flux'][1]]\n",
    "            \n",
    "            # Case where there are brightness error columns\n",
    "            if 'flux_err' in data_dict.keys():                \n",
    "                \n",
    "                flux_error = data.iloc[:,data_dict['flux_err']]\n",
    "                # Creating a new dictionary for the columns above separate data\n",
    "                standard_data = {'ID':ID,'time':time,'flux1':flux1,'flux2':flux2,'flux_error':flux_error}\n",
    "                \n",
    "            # Case were there are no error columns\n",
    "            else:\n",
    "                \n",
    "                standard_data = {'ID':ID,'time':time,'flux1':flux1,'flux2':flux2}\n",
    "                           \n",
    "        \n",
    "        \n",
    "                \n",
    "        # ============Column with Mag_filters and errors==========================\n",
    "        \n",
    "        # Including filters in dataframe\n",
    "        elif 'filters'in data_dict.keys() and 'flux_err' in data_dict.keys():\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; flux = data.iloc[:,data_dict['flux']];\n",
    "            flux_error = data.iloc[:,data_dict['flux_err']]\n",
    "\n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'ID':ID,'time':time,'flux':flux,'flux_error':flux_error,'filters':filters}\n",
    "            \n",
    "        elif 'filters' in data_dict.keys():\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; flux = data.iloc[:,data_dict['flux']];\n",
    "    \n",
    "\n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'ID':ID,'time':time,'flux':flux,'filters':filters}\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        #=================Single Mag Column with and with errors============================\n",
    "        \n",
    "        # Case of single brightness columns    \n",
    "        else:    \n",
    "            \n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; flux = data.iloc[:,data_dict['flux']]; \n",
    "            \n",
    "            if 'flux_err' in data_dict.keys():\n",
    "                \n",
    "                \n",
    "                flux_error = data.iloc[:,data_dict['flux_err']]\n",
    "                # Creating a new dictionary for the columns above separate data\n",
    "                standard_data = {'ID':ID,'time':time,'flux':flux,'flux_error':flux_error}\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                standard_data = {'ID':ID,'time':time,'flux':flux}\n",
    "        \n",
    "        \n",
    "        \n",
    "#         # Separatting the columns as per input dictionary\n",
    "#         ID = data.iloc[:,data_dict['id']]; time = data.iloc[:,data_dict['time']]; \n",
    "#         flux = data.iloc[:,data_dict['flux']]; flux_error = data.iloc[:,data_dict['flux_err']];\n",
    "    \n",
    "#         standard_data = {'ID':ID,'time':time,'flux':flux,'flux_error':flux_error}\n",
    "        \n",
    "#         # Including filters in the dataframe\n",
    "#         if 'filters' in data_dict.keys():\n",
    "            \n",
    "#             filters = data.iloc[:,data_dict['filters']]\n",
    "#             standard_data = {'ID':ID,'time':time,'flux':flux,'flux_error':flux_error,'filters':filters}\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    return pd.DataFrame.from_dict(standard_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/malema/Desktop/Malema_UWC_Work/Data/20121012_02331333_O_CrabNebula_E.dat'\n",
    "\n",
    "dt=read_lc3(flpath=url,data_dict={'time':1,'flux':[2,3],'flux_err':0,'id':3},delim_whitespace=True,header_nrows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>time</th>\n",
       "      <th>flux1</th>\n",
       "      <th>flux2</th>\n",
       "      <th>flux_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.102021</td>\n",
       "      <td>0.106574</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>-0.102021</td>\n",
       "      <td>56212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.108044</td>\n",
       "      <td>0.106574</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.108044</td>\n",
       "      <td>56212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.094419</td>\n",
       "      <td>0.106574</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.094419</td>\n",
       "      <td>56212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.101473</td>\n",
       "      <td>0.106574</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-0.101473</td>\n",
       "      <td>56212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.103084</td>\n",
       "      <td>0.106574</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-0.103084</td>\n",
       "      <td>56212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991389</th>\n",
       "      <td>-0.102278</td>\n",
       "      <td>0.113509</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.102278</td>\n",
       "      <td>56212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991390</th>\n",
       "      <td>-0.099830</td>\n",
       "      <td>0.113509</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>-0.099830</td>\n",
       "      <td>56212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991391</th>\n",
       "      <td>-0.108591</td>\n",
       "      <td>0.113509</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.108591</td>\n",
       "      <td>56212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991392</th>\n",
       "      <td>-0.102246</td>\n",
       "      <td>0.113509</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.102246</td>\n",
       "      <td>56212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991393</th>\n",
       "      <td>-0.104565</td>\n",
       "      <td>0.113509</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.104565</td>\n",
       "      <td>56212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5991394 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID      time     flux1     flux2  flux_error\n",
       "0       -0.102021  0.106574  0.000082 -0.102021       56212\n",
       "1       -0.108044  0.106574  0.000017 -0.108044       56212\n",
       "2       -0.094419  0.106574  0.000017 -0.094419       56212\n",
       "3       -0.101473  0.106574  0.000050 -0.101473       56212\n",
       "4       -0.103084  0.106574  0.000050 -0.103084       56212\n",
       "...           ...       ...       ...       ...         ...\n",
       "5991389 -0.102278  0.113509  0.000017 -0.102278       56212\n",
       "5991390 -0.099830  0.113509  0.000082 -0.099830       56212\n",
       "5991391 -0.108591  0.113509 -0.000015 -0.108591       56212\n",
       "5991392 -0.102246  0.113509 -0.000015 -0.102246       56212\n",
       "5991393 -0.104565  0.113509  0.000017 -0.104565       56212\n",
       "\n",
       "[5991394 rows x 5 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
