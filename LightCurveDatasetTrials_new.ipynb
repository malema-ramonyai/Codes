{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "# from astronomaly.base.base_dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-51ffb2311c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLightCurveDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader_nrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelim_whitespace\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "# from astronomaly.base.base_dataset import Dataset\n",
    "\n",
    "\n",
    "class LightCurveDataset(Dataset):\n",
    "    def __init__(self,data_dict,header_nrows=1,delim_whitespace =False,**kwargs):\n",
    "        \"\"\"\n",
    "        Reads in light curve data from file(s).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            If a single file (of any time) is to be read from, the path can be\n",
    "            given using this kwarg. \n",
    "        directory : str\n",
    "            A directory can be given instead of an explicit list of files. The\n",
    "            child class will load all appropriate files in this directory.\n",
    "        list_of_files : list\n",
    "            Instead of the above, a list of files to be loaded can be\n",
    "            explicitly given.\n",
    "        output_dir : str\n",
    "            The directory to save the log file and all outputs to. Defaults to\n",
    "            './' \n",
    "        \n",
    "        data_dict: Dictionary\n",
    "                It a dictionary with index of the column names corresponding to the \n",
    "                following specific keys: ('time','mag','mag_err','flux','flux_err','filters')\n",
    "                \n",
    "                e.g {'time':1,'mag':2}, were 1 and 2 are column index correpoding to \n",
    "                'time' and 'mag' in the input data \n",
    "                \n",
    "                The user can also provide a list of indices for the 'mag' and 'flux' columns. This is the\n",
    "                case were the brightness is recorded in more than one column.\n",
    "                \n",
    "                e.g {'time':1,'mag':[2,3]} 2 and 3 corresponds to columns with brightness records\n",
    "        \n",
    "        header_nrows: int\n",
    "                The number of rows the header covers in the dataset, by \n",
    "                default 1\n",
    "                \n",
    "         delim_whitespace: bool\n",
    "                Should be True if the data is not separated by a comma, by\n",
    "                default False\n",
    "                \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(data_dict,header_nrows=1,delim_whitespace =False,**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "        self.data_type = 'light_curve'\n",
    "        self.metadata = pd.DataFrame(data=[])\n",
    "        \n",
    "\n",
    "        ##### need to understand this line of code!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # ids = [f.split(os.sep)[-1] for f in self.files]\n",
    "        # self.metadata = pd.DataFrame({'filepath': self.files}, index=ids)\n",
    "\n",
    "        \n",
    "\n",
    "        self.data_dict = data_dict\n",
    "        self.header_nrows = header_nrows\n",
    "        self.delim_whitespace = delim_whitespace\n",
    "     \n",
    "        \n",
    "#         ========================================================================================\n",
    "                                   \n",
    "                                    # Reading the light curve data \n",
    "        \n",
    "#         ========================================================================================\n",
    "\n",
    "        \n",
    "        \n",
    "        # Reading-in the data\n",
    "        \n",
    "        \n",
    "        \n",
    "        # ===================Case for multiple files of light curve data================================\n",
    "        try:\n",
    "\n",
    "            data=pd.concat([pd.read_csv(self.files[0],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None),\n",
    "                               \n",
    "                               pd.read_csv(self.files[1],skiprows=self.header_nrows,\n",
    "                                           delim_whitespace=self.delim_whitespace,header=None)])\n",
    "            \n",
    "            \n",
    "\n",
    "            for fl in range(2,len(self.files)):\n",
    "\n",
    "                data=pd.concat([data, pd.read_csv(self.files[fl],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None)])\n",
    "                \n",
    "        \n",
    "        # ===================Case for single file of light curve data==================================\n",
    "        except IndexError:\n",
    "            \n",
    "            \n",
    "            data = pd.read_csv(self.files[0],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None)\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        # ==================Magnitudes==================================\n",
    "        # ==============================================================\n",
    "        Id = data.iloc[:,self.data_dict['id']]\n",
    "        time = data.iloc[:,self.data_dict['time']]\n",
    "        \n",
    "        standard_data = {'ID':Id,'time':time}\n",
    "        \n",
    "        if 'mag' in self.data_dict.keys(): \n",
    "            \n",
    "            \n",
    "            # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            try:\n",
    "                \n",
    "                \n",
    "        \n",
    "                for i in range(len(self.data_dict['mag'])):\n",
    "                    \n",
    "                    \n",
    "                    # Separatting the columns as per input dictionary\n",
    "    #             \n",
    "\n",
    "                    # Case where there are brightness error columns\n",
    "                    if 'mag_err' in self.data_dict.keys():                \n",
    "\n",
    "                        # Creating a new dictionary for the columns above separate data\n",
    "                        standard_data.update({'mag'+str(i+1):data.iloc[:,self.data_dict['mag'][i]],\n",
    "                                              'mag_error'+str(i+1):data.iloc[:,self.data_dict['mag_err'][i]]})\n",
    "\n",
    "                    # Case were there are no error columns\n",
    "                    else:\n",
    "\n",
    "                        standard_data.update({'mag'+str(i+1):data.iloc[:,self.data_dict['mag'][i]]})\n",
    "                    \n",
    "                    \n",
    "            \n",
    "                \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "            except TypeError:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']]; \n",
    "                \n",
    "                if 'mag_err' in self.data_dict.keys():\n",
    "                    \n",
    "                    \n",
    "                    mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data.update({'mag':mag,'mag_error':mag_error})\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    standard_data.update({'mag':mag})\n",
    "                            \n",
    "            \n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            if 'filters'in self.data_dict.keys() and 'mag_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "                mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'mag':mag,'mag_error':mag_error,'filters':filters})\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'mag':mag,'filters':filters})\n",
    "                \n",
    "                \n",
    "                \n",
    "                    \n",
    "                    \n",
    "    #-----------------------------------------------------------------------------------------------------------------                \n",
    "                \n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````      \n",
    "    #============================================Fluxes===============================================================\n",
    "    #=================================================================================================================\n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            \n",
    "                    # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            try:\n",
    "                \n",
    "                \n",
    "        \n",
    "                for i in range(len(self.data_dict['flux'])):\n",
    "                    \n",
    "                    \n",
    "                    # Separatting the columns as per input dictionary\n",
    "    #             \n",
    "\n",
    "                    # Case where there are brightness error columns\n",
    "                    if 'flux_err' in self.data_dict.keys():                \n",
    "\n",
    "                        # Creating a new dictionary for the columns above separate data\n",
    "                        standard_data.update({'flux'+str(i+1):data.iloc[:,self.data_dict['flux'][i]],\n",
    "                                              'flux_error'+str(i+1):data.iloc[:,self.data_dict['flux_err'][i]]})\n",
    "                    # Case were there are no error columns\n",
    "                    else:\n",
    "\n",
    "                        standard_data.update({'flux'+str(i+1):data.iloc[:,self.data_dict['flux'][i]]})\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            except TypeError:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']]; \n",
    "\n",
    "                if 'flux_err' in self.data_dict.keys():\n",
    "\n",
    "\n",
    "                    flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data.update({'flux':flux,'flux_error':flux_error})\n",
    "\n",
    "                else:\n",
    "\n",
    "                    standard_data.update({'flux':flux})\n",
    "\n",
    "\n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            if 'filters'in self.data_dict.keys() and 'flux_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "                flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'flux':flux,'flux_error':flux_error,'filters':filters})\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'flux':flux,'filters':filters})\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "          \n",
    "            \n",
    "        ids = np.unique(standard_data['ID'])   \n",
    "        self.metadata = pd.DataFrame({'ID': ids}, index=ids)\n",
    "        self.light_curves_data = pd.DataFrame.from_dict(standard_data)\n",
    "    \n",
    "    def get_display_data(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single instance of the dataset in a form that is ready to be\n",
    "        displayed by the web front end.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : str\n",
    "            Index (should be a string to avoid ambiguity)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            json-compatible dictionary of the light curve data\n",
    "        \"\"\"\n",
    " \n",
    "\n",
    "\n",
    "        # All the standard columns are included here\n",
    "        data_col = ['mag','flux','mag1','mag2','flux1','flux2','filters']\n",
    "\n",
    "        err_col = ['mag_error','flux_error']\n",
    "\n",
    "        out_dict = {}\n",
    "\n",
    "\n",
    "            \n",
    "        # Reading in the light curve data\n",
    "\n",
    "        light_curve = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "\n",
    "        # Data and error index \n",
    "        mag_indx = [cl for cl in data_col if cl in light_curve.columns.values.tolist()] \n",
    "        err_indx = [cl for cl in err_col if cl in light_curve.columns.values.tolist()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Returns true if we have error columns\n",
    "        if err_col[0] in light_curve.columns.values.tolist() or err_col[1] in light_curve.columns.values.tolist():\n",
    "\n",
    "\n",
    "            light_curve['err_lower'] = light_curve[mag_indx].values - light_curve[err_indx].values\n",
    "            light_curve['err_upper'] = light_curve[mag_indx].values + light_curve[err_indx].values\n",
    "            lc_errs = light_curve[['time', 'err_lower', 'err_upper']]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # inserting the time column to data and adding 'data'\n",
    "        # and 'errors' to out_dict\n",
    "        mag_indx.insert(0,'time')\n",
    "        out_dict['data'] = light_curve[mag_indx].values.tolist()\n",
    "        out_dict['errors'] = lc_errs.values.tolist()\n",
    "\n",
    "        \n",
    "        return out_dict\n",
    "    \n",
    "\n",
    "    def get_sample(self,idx):\n",
    "        \n",
    "        \n",
    "        # All the standard columns for feature extraction \n",
    "        data_col = ['time','mag','flux','mag1','mag2','flux1','flux2','mag_error','flux_error']\n",
    "\n",
    "        \n",
    "\n",
    "        # empty pandas dataframe to update as per data_col\n",
    "        out_data = pd.DataFrame({})\n",
    "        try:\n",
    "\n",
    "            \n",
    "   \n",
    "            # Choosing light curve values for a specific ID\n",
    "            light_curve = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "            \n",
    "            \n",
    "            sample_data = []\n",
    "            # Getting the columns that correspond to lc columns \n",
    "            for cl in data_col:\n",
    "                \n",
    "                if cl in light_curve.columns.values.tolist():\n",
    "\n",
    "                    out_data[cl] = light_curve[cl].values.tolist()\n",
    "                    sample_data.append(out_data[cl])\n",
    "            \n",
    "                \n",
    "            \n",
    "        except (pd.errors.ParserError, pd.errors.EmptyDataError, FileNotFoundError) as e:\n",
    "            print('Error parsing file', flpath)\n",
    "            print('Error message:')\n",
    "            print(e)\n",
    "            out_dict = {'data': [], 'errors': []}\n",
    "            \n",
    "            \n",
    "            \n",
    "        return sample_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "# from astronomaly.base.base_dataset import Dataset\n",
    "\n",
    "\n",
    "class LightCurveDataset(object):\n",
    "    def __init__(self,data_dict,files,header_nrows=1,delim_whitespace =False,**kwargs):\n",
    "        \"\"\"\n",
    "        Reads in light curve data from file(s).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            If a single file (of any time) is to be read from, the path can be\n",
    "            given using this kwarg. \n",
    "        directory : str\n",
    "            A directory can be given instead of an explicit list of files. The\n",
    "            child class will load all appropriate files in this directory.\n",
    "        list_of_files : list\n",
    "            Instead of the above, a list of files to be loaded can be\n",
    "            explicitly given.\n",
    "        output_dir : str\n",
    "            The directory to save the log file and all outputs to. Defaults to\n",
    "            './' \n",
    "        \n",
    "        data_dict: Dictionary\n",
    "                It a dictionary with index of the column names corresponding to the \n",
    "                following specific keys: ('time','mag','mag_err','flux','flux_err','filters')\n",
    "                \n",
    "                e.g {'time':1,'mag':2}, were 1 and 2 are column index correpoding to \n",
    "                'time' and 'mag' in the input data .\n",
    "                \n",
    "                The user can also provide a list of indices for the 'mag' and 'flux' columns. This is the\n",
    "                case were the brightness is recorded in more than one column.\n",
    "                \n",
    "                e.g {'time':1,'mag':[2,3]} 2 and 3 corresponds to columns with brightness records\n",
    "        \n",
    "        header_nrows: int\n",
    "                The number of rows the header covers in the dataset, by \n",
    "                default 1\n",
    "                \n",
    "         delim_whitespace: bool\n",
    "                Should be True if the data is not separated by a comma, by\n",
    "                default False\n",
    "                \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "#         super().__init__(data_dict,header_nrows=1,delim_whitespace =False,**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "        self.data_type = 'light_curve'\n",
    "        self.metadata = pd.DataFrame(data=[])\n",
    "        \n",
    "\n",
    "        ##### need to understand this line of code!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # ids = [f.split(os.sep)[-1] for f in self.files]\n",
    "        # self.metadata = pd.DataFrame({'filepath': self.files}, index=ids)\n",
    "\n",
    "        \n",
    "\n",
    "        self.data_dict = data_dict\n",
    "        self.header_nrows = header_nrows\n",
    "        self.delim_whitespace = delim_whitespace\n",
    "        self.files = files\n",
    "     \n",
    "        \n",
    "#         ========================================================================================\n",
    "                                   \n",
    "                                    # Reading the light curve data \n",
    "        \n",
    "#         ========================================================================================\n",
    "\n",
    "#     @staticmethod\n",
    "#     def read_lc_from_file(self,flpath):\n",
    "\n",
    "        \n",
    "        '''Function to read the lc from the data\n",
    "        \n",
    "        Input:\n",
    "        flpath: the location of the file\n",
    "        \n",
    "    \n",
    "                \n",
    "        Output:\n",
    "       standardized pandas dataframe with lc data'''\n",
    "        \n",
    "        \n",
    "        # Reading-in the data\n",
    "        \n",
    "        \n",
    "        \n",
    "        # ===================Case for multiple files of light curve data================================\n",
    "        try:\n",
    "\n",
    "            data=pd.concat([pd.read_csv(self.files[0],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None),\n",
    "                               \n",
    "                               pd.read_csv(self.files[1],skiprows=self.header_nrows,\n",
    "                                           delim_whitespace=self.delim_whitespace,header=None)])\n",
    "            \n",
    "            \n",
    "\n",
    "            for fl in range(2,len(self.files)):\n",
    "\n",
    "                data=pd.concat([data, pd.read_csv(self.files[fl],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None)])\n",
    "                \n",
    "        \n",
    "        # ===================Case for single file of light curve data==================================\n",
    "        except IndexError:\n",
    "            \n",
    "            \n",
    "            data = pd.read_csv(self.files[0],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None)\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # ==================Magnitudes==================================\n",
    "        # ==============================================================\n",
    "        ID = data.iloc[:,self.data_dict['id']]\n",
    "        time = data.iloc[:,self.data_dict['time']]\n",
    "        \n",
    "        standard_data = {'ID':ID,'time':time}\n",
    "        if 'mag' in self.data_dict.keys(): \n",
    "            \n",
    "            \n",
    "            # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            try:\n",
    "                \n",
    "                \n",
    "        \n",
    "                for i in range(len(self.data_dict['mag'])):\n",
    "                    \n",
    "                    \n",
    "                    # Separatting the columns as per input dictionary\n",
    "    #             \n",
    "\n",
    "                    # Case where there are brightness error columns\n",
    "                    if 'mag_err' in self.data_dict.keys():                \n",
    "\n",
    "\n",
    "                        # Creating a new dictionary for the columns above separate data\n",
    "                        standard_data.update({'mag'+str(i+1):data.iloc[:,self.data_dict['mag'][i]],\n",
    "                                              'mag_error'+str(i+1):data.iloc[:,self.data_dict['mag_err'][i]]})\n",
    "                    # Case were there are no error columns\n",
    "                    else:\n",
    "\n",
    "                        standard_data.update({'mag'+str(i+1):data.iloc[:,self.data_dict['mag'][i]]})\n",
    "                    \n",
    "                    \n",
    "            \n",
    "                \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "            except TypeError:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']]; \n",
    "                \n",
    "                if 'mag_err' in self.data_dict.keys():\n",
    "                    \n",
    "                    \n",
    "                    mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "                    # Updating the 'standard' dictionary for the columns above separate data\n",
    "                    standard_data.update({'mag':mag,'mag_error':mag_error})\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    standard_data.update({'mag':mag})\n",
    "                            \n",
    "            \n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            if 'filters'in self.data_dict.keys() and 'mag_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "                mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'mag':mag,'mag_error':mag_error,'filters':filters})\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'mag':mag,'filters':filters})\n",
    "                \n",
    "                \n",
    "                \n",
    "                    \n",
    "                    \n",
    "    #-----------------------------------------------------------------------------------------------------------------                \n",
    "                \n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````      \n",
    "    #============================================Fluxes===============================================================\n",
    "    #=================================================================================================================\n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            \n",
    "                    # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            try:\n",
    "                \n",
    "                \n",
    "        \n",
    "                for i in range(len(self.data_dict['flux'])):\n",
    "                    \n",
    "                    \n",
    "                    # Separatting the columns as per input dictionary\n",
    "    #             \n",
    "\n",
    "                    # Case were there are brightness error columns\n",
    "                    if 'flux_err' in self.data_dict.keys():                \n",
    "\n",
    "                        flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "                        # Creating a new dictionary for the columns above separate data\n",
    "                        standard_data.update({'flux'+str(i+1):data.iloc[:,self.data_dict['flux'][i]],\n",
    "                                              'flux_error'+str(i+1):data.iloc[:,self.data_dict['flux_err'][i]]})\n",
    "                    # Case were there are no error columns\n",
    "                    else:\n",
    "\n",
    "                        standard_data.update({'flux'+str(i+1):data.iloc[:,self.data_dict['flux'][i]]})\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            except TypeError:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']]; \n",
    "\n",
    "                if 'flux_err' in self.data_dict.keys():\n",
    "\n",
    "\n",
    "                    flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data.update({'flux':flux,'flux_error':flux_error})\n",
    "\n",
    "                else:\n",
    "\n",
    "                    standard_data.update({'flux':flux})\n",
    "\n",
    "\n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            if 'filters'in self.data_dict.keys() and 'flux_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "                flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'flux':flux,'flux_error':flux_error,'filters':filters})\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'flux':flux,'filters':filters})\n",
    "                \n",
    "                \n",
    "                   \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "              \n",
    "        ids = np.unique(standard_data['ID'])   \n",
    "        self.metadata = pd.DataFrame({'ID': ids}, index=ids)\n",
    "        self.light_curves_data = pd.DataFrame.from_dict(standard_data)\n",
    "        \n",
    "    \n",
    "    def get_display_data(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single instance of the dataset in a form that is ready to be\n",
    "        displayed by the web front end.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : str\n",
    "            Index (should be a string to avoid ambiguity)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            json-compatible dictionary of the light curve data\n",
    "        \"\"\"\n",
    " \n",
    "\n",
    "\n",
    "        # All the standard columns are included here\n",
    "        data_col = ['mag','flux','mag1','mag2','flux1','flux2','filters']\n",
    "\n",
    "        err_col = ['mag_error','flux_error']\n",
    "\n",
    "        out_dict = {}\n",
    "\n",
    "\n",
    "            \n",
    "        # Reading in the light curve data\n",
    "\n",
    "        light_curve = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "\n",
    "        # Data and error index \n",
    "        mag_indx = [cl for cl in data_col if cl in light_curve.columns.values.tolist()] \n",
    "        err_indx = [cl for cl in err_col if cl in light_curve.columns.values.tolist()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Returns true if we have error columns\n",
    "        if err_col[0] in light_curve.columns.values.tolist() or err_col[1] in light_curve.columns.values.tolist():\n",
    "\n",
    "\n",
    "            light_curve['err_lower'] = light_curve[mag_indx].values - light_curve[err_indx].values\n",
    "            light_curve['err_upper'] = light_curve[mag_indx].values + light_curve[err_indx].values\n",
    "            lc_errs = light_curve[['time', 'err_lower', 'err_upper']]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # inserting the time column to data and adding 'data'\n",
    "        # and 'errors' to out_dict\n",
    "        mag_indx.insert(0,'time')\n",
    "        out_dict['data'] = light_curve[mag_indx].values.tolist()\n",
    "        out_dict['errors'] = lc_errs.values.tolist()\n",
    "\n",
    "            \n",
    "\n",
    "        return out_dict\n",
    "    \n",
    "\n",
    "    def get_sample(self,idx):\n",
    "\n",
    "        \n",
    "  \n",
    "        # Choosing light curve values for a specific ID\n",
    "        light_curve_sample = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "        \n",
    "        return light_curve_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path2 = ['/home/malema/Desktop/Malema_UWC_Work/Data/test_set_batch1.csv','/home/malema/Desktop/Malema_UWC_Work/Data/test_set_batch1.csv']\n",
    "         \n",
    "#          ,'/home/malema/Desktop/Malema_UWC_Work/Data/test_set_batch1.csv']\n",
    "\n",
    "md = LightCurveDataset(data_dict={'time':1,'flux':3,'flux_err':4,'id':0,'fliters':2},files=path2,\n",
    "                     delim_whitespace=False,header_nrows=1)\n",
    "\n",
    "\n",
    "\n",
    "dsp = md.get_display_data(idx=14)\n",
    " \n",
    "# lc[lc['Id']==40]\n",
    "\n",
    "z = md.light_curves_data\n",
    "\n",
    "ls = ['mag']\n",
    "ls.insert(0,'time')\n",
    "# md.get_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     ID        time       flux  flux_error\n",
       "0    13  59798.3205  -1.299735    1.357315\n",
       "1    13  59798.3281  -2.095392    1.148654\n",
       "2    13  59798.3357  -0.923794    1.763655\n",
       "3    13  59798.3466  -4.009815    2.602911\n",
       "4    13  59798.3576  -3.403503    5.367328\n",
       "..   ..         ...        ...         ...\n",
       "325  13  60652.1289   2.063019    0.939241\n",
       "326  13  60652.1365   0.914091    1.117558\n",
       "327  13  60652.1441   8.505517    1.381162\n",
       "328  13  60652.1550  20.247869    2.050198\n",
       "329  13  60652.1660   4.584575    5.200393\n",
       "\n",
       "[660 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>time</th>\n      <th>flux</th>\n      <th>flux_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13</td>\n      <td>59798.3205</td>\n      <td>-1.299735</td>\n      <td>1.357315</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13</td>\n      <td>59798.3281</td>\n      <td>-2.095392</td>\n      <td>1.148654</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13</td>\n      <td>59798.3357</td>\n      <td>-0.923794</td>\n      <td>1.763655</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13</td>\n      <td>59798.3466</td>\n      <td>-4.009815</td>\n      <td>2.602911</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13</td>\n      <td>59798.3576</td>\n      <td>-3.403503</td>\n      <td>5.367328</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>325</th>\n      <td>13</td>\n      <td>60652.1289</td>\n      <td>2.063019</td>\n      <td>0.939241</td>\n    </tr>\n    <tr>\n      <th>326</th>\n      <td>13</td>\n      <td>60652.1365</td>\n      <td>0.914091</td>\n      <td>1.117558</td>\n    </tr>\n    <tr>\n      <th>327</th>\n      <td>13</td>\n      <td>60652.1441</td>\n      <td>8.505517</td>\n      <td>1.381162</td>\n    </tr>\n    <tr>\n      <th>328</th>\n      <td>13</td>\n      <td>60652.1550</td>\n      <td>20.247869</td>\n      <td>2.050198</td>\n    </tr>\n    <tr>\n      <th>329</th>\n      <td>13</td>\n      <td>60652.1660</td>\n      <td>4.584575</td>\n      <td>5.200393</td>\n    </tr>\n  </tbody>\n</table>\n<p>660 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "md.get_sample(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8f802617f0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.array(dsp['data'])[:,0],np.array(dsp['data'])[:,1],'.')\n",
    "\n",
    "# np.array(dsp['data'])[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = md.light_curves_data[['mag']].values - md.light_curves_data[['ID']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time', 'mag_error', 'flux_error']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "err_col = ['mag_error','flux_error']\n",
    "\n",
    "err_indx = [cl for cl in err_col if cl in z.columns.values.tolist()]\n",
    "\n",
    "err_indx.append('time')\n",
    "\n",
    "err_col.insert(0,'time')\n",
    "\n",
    "# err_indx\n",
    "\n",
    "err_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing if get_sample works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malema/anaconda3/lib/python3.8/site-packages/feets/extractors/core.py:234: ExtractorWarning: The original FATS documentation says that the result of AndersonDarling must be ~0.25 for gausian distribution but the  result is ~-0.60\n",
      "  warnings.warn(w, ExtractorWarning)\n"
     ]
    },
    {
     "ename": "DataRequiredError",
     "evalue": "magnitude",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataRequiredError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bb6cac4902c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdsp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/feets/core.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, time, magnitude, error, magnitude2, aligned_time, aligned_magnitude, aligned_magnitude2, aligned_error, aligned_error2)\u001b[0m\n\u001b[1;32m    277\u001b[0m                 aligned_error=None, aligned_error2=None):\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         kwargs = self.dict_data_as_array({\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0mDATA_TIME\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mDATA_MAGNITUDE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/feets/core.py\u001b[0m in \u001b[0;36mdict_data_as_array\u001b[0;34m(self, d)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_required_data\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mDataRequiredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0marray_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marray_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataRequiredError\u001b[0m: magnitude"
     ]
    }
   ],
   "source": [
    "import feets\n",
    "\n",
    "# The features from the light curves\n",
    "fs = feets.FeatureSpace(\n",
    "\n",
    "    only=['StructureFunction_index_21','Mean','AndersonDarling','Amplitude','Freq1_harmonics_rel_phase_1',\n",
    "          'MaxSlope','LinearTrend','Beyond1Std','CAR_sigma','Period_fit','SlottedA_length',\n",
    "          'SmallKurtosis','Autocor_length','Con','Eta_e'] ) \n",
    "\n",
    "lc = dsp\n",
    "features, values = fs.extract(*lc)\n",
    "val = values.tolist()\n",
    "\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [1,2,3,50]\n",
    "metadata = pd.DataFrame({'filepath': files}, index=[20,2,3,50])\n",
    "flpath = metadata['filepath'].iloc[3]\n",
    "# metadata.keys()\n",
    "\n",
    "flpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.iloc[0].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metadata)\n",
    "\n",
    "dt = pd.read_csv(path2)\n",
    "\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt1 = pd.DataFrame({'time':dt.mjd,'flux':dt.flux, 'flux_err':dt.flux_err }, index=dt.object_id.values)\n",
    "\n",
    "dt1 = {'time':[1,2], 'mag':[2,4]}\n",
    "dt2 = {'time':[1,2], 'mag':[1,2]}\n",
    "dt3 = {'time':[2,3], 'mag':[2,3]}\n",
    "dt4 = {'time':[0,0], 'mag':[0,0]}\n",
    "# dt3 = {'time':[2,3], 'mag':[2,3]}\n",
    "\n",
    "\n",
    "dt1 = pd.DataFrame(dt1);dt2 = pd.DataFrame(dt2); dt3 = pd.DataFrame(dt3);dt4 = pd.DataFrame(dt4)\n",
    "\n",
    "# print(dt1)\n",
    "# print(dt2)\n",
    "# print(dt3)\n",
    "\n",
    "lst = [dt1,dt2]\n",
    "try:\n",
    "\n",
    "    new_dat=pd.concat([lst[0],lst[1]])\n",
    "\n",
    "    for i in range(2,len(lst)):\n",
    "\n",
    "        new_dat=pd.concat([new_dat,lst[i]])\n",
    "        \n",
    "except IndexError:\n",
    "    \n",
    "    new_dat = lst[0]\n",
    "\n",
    "new_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1.loc[13,'time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0,1,50)\n",
    "\n",
    "y = np.sin(x)\n",
    "\n",
    "\n",
    "plt.plot(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrition = {'food':['mango','banana','pap','eggs'],'kcal':[10,30,80,100],'kJ':np.array([90,30,10,5])}\n",
    " \n",
    "nutrition['kJ'] = nutrition['kJ'] + 10\n",
    "\n",
    "nutrition = pd.DataFrame.from_dict(nutrition)\n",
    "\n",
    "nutrition\n",
    "\n",
    "for kj in nutrition['food']:\n",
    "    \n",
    "    print(kj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(nutrition.kcal,nutrition.kJ,'*r')\n",
    "plt.xlabel('kcal')\n",
    "plt.ylabel('kJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictn = {}\n",
    "dictn1 = {}\n",
    "\n",
    "fl1 = [1,2,3]\n",
    "fl2 = [4,6,1]\n",
    "fl3 = [20,4,5]\n",
    "fl4 = [0,0,0]\n",
    "\n",
    "dct = {'fl3':fl4}\n",
    "# dct = pd.DataFrame.from_dict(dct)\n",
    "\n",
    "\n",
    "files = [fl1,fl2,fl3]\n",
    "files2 = [fl1,fl2,fl3]\n",
    "\n",
    "for fls in range(len(files)):\n",
    "    \n",
    "    dictn['fl'+str(fls)] = files[fls]\n",
    "\n",
    "dt = pd.DataFrame.from_dict(dictn)\n",
    "    \n",
    "for fls in range(len(files2)):\n",
    "    \n",
    "    dictn1['fl'+str(fls)] = files2[fls]\n",
    "    \n",
    "dt1 = pd.DataFrame.from_dict(dictn1) \n",
    "\n",
    "dt1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'malema'+'brigdet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([dt,dt1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dct['dt','ft','gt'] = [1,1,1],[2,2,2],[3,3,3]\n",
    "\n",
    "dictn = {}\n",
    "dct = {'fl3':fl4}\n",
    "\n",
    "\n",
    "dct.update({'dt':[1,1,1],'ft':[2,2,2],'gt':[3,3,3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3])\n",
    "\n",
    "\n",
    "for i in range(len(x)):\n",
    "    \n",
    "    x[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_columns = [1,2,3]\n",
    "\n",
    "mags = {}\n",
    "\n",
    "cl = np.zeros(len(mag_columns))\n",
    "\n",
    "for i in range(len(mag_columns)):\n",
    "    \n",
    "#     cl[i] = mag_columns[i]\n",
    "    \n",
    "    mags['mag'+str(i)] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e9b457b5ae38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load data and train Anomaly Detector as usual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIsolationForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Load data and train Anomaly Detector as usual \n",
    "X_train, X_test, ...\n",
    "est = IsolationForest()\n",
    "est.fit(...)\n",
    "\n",
    "# Create shap values and plot them\n",
    "X_explain = X_test\n",
    "shap_values = shap.TreeExplainer(est).shap_values(X_explain)\n",
    "shap.summary_plot(shap_values, X_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/malema/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - shap\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.9.2                |   py38h578d9bd_0         3.0 MB  conda-forge\n",
      "    python_abi-3.8             |           1_cp38           4 KB  conda-forge\n",
      "    shap-0.37.0                |   py38h0ef3d22_0         508 KB  conda-forge\n",
      "    slicer-0.0.7               |     pyhd8ed1ab_0          16 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  python_abi         conda-forge/linux-64::python_abi-3.8-1_cp38\n",
      "  shap               conda-forge/linux-64::shap-0.37.0-py38h0ef3d22_0\n",
      "  slicer             conda-forge/noarch::slicer-0.0.7-pyhd8ed1ab_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  conda               pkgs/main::conda-4.9.2-py38h06a4308_0 --> conda-forge::conda-4.9.2-py38h578d9bd_0\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? ^C\n",
      "\n",
      "CondaSystemExit: \n",
      "Operation aborted.  Exiting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}