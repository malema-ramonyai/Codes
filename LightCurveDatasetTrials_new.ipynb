{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "# from astronomaly.base.base_dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-757f105b7d85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLightCurveDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader_nrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelim_whitespace\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "# from astronomaly.base.base_dataset import Dataset\n",
    "\n",
    "\n",
    "class LightCurveDataset(Dataset):\n",
    "    def __init__(self,data_dict,header_nrows=1,delim_whitespace =False,**kwargs):\n",
    "        \"\"\"\n",
    "        Reads in light curve data from file(s).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            If a single file (of any time) is to be read from, the path can be\n",
    "            given using this kwarg. \n",
    "        directory : str\n",
    "            A directory can be given instead of an explicit list of files. The\n",
    "            child class will load all appropriate files in this directory.\n",
    "        list_of_files : list\n",
    "            Instead of the above, a list of files to be loaded can be\n",
    "            explicitly given.\n",
    "        output_dir : str\n",
    "            The directory to save the log file and all outputs to. Defaults to\n",
    "            './' \n",
    "        \n",
    "        data_dict: Dictionary\n",
    "                It a dictionary with index of the column names corresponding to the \n",
    "                following specific keys: ('time','mag','mag_err','flux','flux_err','filters')\n",
    "                \n",
    "                e.g {'time':1,'mag':2}, were 1 and 2 are column index correpoding to \n",
    "                'time' and 'mag' in the input data \n",
    "        \n",
    "        header_nrows: int\n",
    "                The number of rows the header covers in the dataset, by \n",
    "                default 1\n",
    "                \n",
    "         delim_whitespace: bool\n",
    "                Should be True if the data is not separated by a comma, by\n",
    "                default False\n",
    "                \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(data_dict,header_nrows=1,delim_whitespace =False,**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "        self.data_type = 'light_curve'\n",
    "        self.metadata = pd.DataFrame(data=[])\n",
    "        \n",
    "\n",
    "        ##### need to understand this line of code!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # ids = [f.split(os.sep)[-1] for f in self.files]\n",
    "        # self.metadata = pd.DataFrame({'filepath': self.files}, index=ids)\n",
    "\n",
    "        \n",
    "\n",
    "        self.data_dict = data_dict\n",
    "        self.header_nrows = header_nrows\n",
    "        self.delim_whitespace = delim_whitespace\n",
    "     \n",
    "        \n",
    "#         ========================================================================================\n",
    "                                   \n",
    "                                    # Reading the light curve data \n",
    "        \n",
    "#         ========================================================================================\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # Reading-in the data\n",
    "        \n",
    "        for obj in self.files:\n",
    "            data = pd.read_csv(self.files[obj],skiprows=self.header_nrows,delim_whitespace=self.delim_whitespace,header=None)\n",
    "        \n",
    "        \n",
    "        # ==================Magnitudes==================================\n",
    "        # ==============================================================\n",
    "        ID = data.iloc[:,self.data_dict['id']]\n",
    "        if 'mag' in self.data_dict.keys(): \n",
    "            \n",
    "            \n",
    "            # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            if type(self.data_dict['mag']) == list:\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag1 = data.iloc[:,self.data_dict['mag'][0]];\n",
    "                mag2 = data.iloc[:,self.data_dict['mag'][1]]\n",
    "                \n",
    "                # Case where there are brightness error columns\n",
    "                if 'mag_err' in self.data_dict.keys():                \n",
    "                    \n",
    "                    mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data = {'ID':ID,'time':time,'mag1':mag1,'mag2':mag2,'mag_error':mag_error}\n",
    "                    \n",
    "                # Case were there are no error columns\n",
    "                else:\n",
    "                    \n",
    "                    standard_data = {'ID':ID,'time':time,'mag1':mag1,'mag2':mag2}\n",
    "                            \n",
    "            \n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            elif 'filters'in self.data_dict.keys() and 'mag_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "                mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data = {'ID':ID,'time':time,'mag':mag,'mag_error':mag_error,'filters':filters}\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data = {'ID':ID,'time':time,'mag':mag,'filters':filters}\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "            else:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']]; \n",
    "                \n",
    "                if 'mag_err' in self.data_dict.keys():\n",
    "                    \n",
    "                    \n",
    "                    mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data = {'ID':ID,'time':time,'mag':mag,'mag_error':mag_error}\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    standard_data = {'ID':ID,'time':time,'mag':mag}\n",
    "                    \n",
    "                    \n",
    "    #-----------------------------------------------------------------------------------------------------------------                \n",
    "                \n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````      \n",
    "    #============================================Fluxes===============================================================\n",
    "    #=================================================================================================================\n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            \n",
    "                    # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            if type(self.data_dict['flux']) == list:\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux1 = data.iloc[:,self.data_dict['flux'][0]];\n",
    "                flux2 = data.iloc[:,self.data_dict['flux'][1]]\n",
    "                \n",
    "                # Case where there are brightness error columns\n",
    "                if 'flux_err' in self.data_dict.keys():                \n",
    "                    \n",
    "                    flux_error = self.data.iloc[:,self.data_dict['flux_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data = {'ID':ID,'time':time,'flux1':flux1,'flux2':flux2,'flux_error':flux_error}\n",
    "                    \n",
    "                # Case were there are no error columns\n",
    "                else:\n",
    "                    \n",
    "                    standard_data = {'ID':ID,'time':time,'flux1':flux1,'flux2':flux2}\n",
    "                            \n",
    "            \n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            elif 'filters'in self.data_dict.keys() and 'flux_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "                flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data = {'ID':ID,'time':time,'flux':flux,'flux_error':flux_error,'filters':filters}\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data = {'ID':ID,'time':time,'flux':flux,'filters':filters}\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "            else:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']]; \n",
    "                \n",
    "                if 'flux_err' in self.data_dict.keys():\n",
    "                    \n",
    "                    \n",
    "                    flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data = {'ID':ID,'time':time,'flux':flux,'flux_error':flux_error}\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    standard_data = {'ID':ID,'time':time,'flux':flux}\n",
    "            \n",
    "        ids = np.unique(standard_data['ID'])   \n",
    "        self.metadata = pd.DataFrame({'ID': ids}, index=ids)\n",
    "        self.light_curves_data = pd.DataFrame.from_dict(standard_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def get_display_data(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single instance of the dataset in a form that is ready to be\n",
    "        displayed by the web front end.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : str\n",
    "            Index (should be a string to avoid ambiguity)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            json-compatible dictionary of the light curve data\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # All the standard columns are included here\n",
    "        data_col = ['time','mag','flux','mag1','mag2','flux1','flux2','filters']\n",
    "\n",
    "        err_col = ['mag_error','flux_error']\n",
    "\n",
    "        out_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "\n",
    "            \n",
    "            # Reading in the light curves data for a specific ID\n",
    "            light_curve = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "            \n",
    "            # Data and error index \n",
    "            data_indx = [cl for cl in data_col if cl in light_curve.columns.values.tolist()] \n",
    "            err_indx = [cl for cl in err_col if cl in light_curve.columns.values.tolist()]\n",
    "\n",
    "            \n",
    "            # Getting both the data and error columns as per index\n",
    "            out_dict['data'] = light_curve[data_indx].values.tolist()\n",
    "            \n",
    "            \n",
    "            # Returns true if we have error columns\n",
    "            if err_col[0] in light_curve.columns.values.tolist() or err_col[1] in light_curve.columns.values.tolist():\n",
    "                lc_errs = light_curve[err_indx]\n",
    "                out_dict['errors'] = lc_errs.values.tolist()\n",
    "                \n",
    "             \n",
    "\n",
    "                \n",
    "\n",
    "        except (pd.errors.ParserError, pd.errors.EmptyDataError, FileNotFoundError) as e:\n",
    "            print('Error parsing file', flpath)\n",
    "            print('Error message:')\n",
    "            print(e)\n",
    "            out_dict = {'data': [], 'errors': []}\n",
    "\n",
    "        return out_dict\n",
    "    \n",
    "\n",
    "    def get_sample(self,idx):\n",
    "        \n",
    "        \n",
    "        # All the standard columns for feature extraction \n",
    "        data_col = ['time','mag','flux','mag1','mag2','flux1','flux2','mag_error','flux_error']\n",
    "\n",
    "\n",
    "    \n",
    "        metadata = self.metadata\n",
    "\n",
    "        ##### need to understand this line of code!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "        # flpath = metadata[idx]['filepath'].iloc[0]\n",
    "\n",
    "        # empty pandas dataframe to update as per data_col\n",
    "        out_data = pd.DataFrame({})\n",
    "        try:\n",
    "\n",
    "            \n",
    "            # Reading in the light curve data\n",
    "#             light_curve = self.read_lc_from_file(flpath)\n",
    "            \n",
    "            # Choosing light curve values for a specific ID\n",
    "            light_curve = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "            \n",
    "            \n",
    "            sample_data = []\n",
    "            # Getting the columns that correspond to lc columns \n",
    "            for cl in data_col:\n",
    "                \n",
    "                if cl in light_curve.columns.values.tolist():\n",
    "\n",
    "                    out_data[cl] = light_curve[cl].values.tolist()\n",
    "                    sample_data.append(out_data[cl])\n",
    "            \n",
    "                \n",
    "            return sample_data\n",
    "                \n",
    "             \n",
    "\n",
    "                \n",
    "\n",
    "        except (pd.errors.ParserError, pd.errors.EmptyDataError, FileNotFoundError) as e:\n",
    "            print('Error parsing file', flpath)\n",
    "            print('Error message:')\n",
    "            print(e)\n",
    "            out_dict = {'data': [], 'errors': []}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "# from astronomaly.base.base_dataset import Dataset\n",
    "\n",
    "\n",
    "class LightCurveDataset(object):\n",
    "    def __init__(self,data_dict,files,header_nrows=1,delim_whitespace =False,**kwargs):\n",
    "        \"\"\"\n",
    "        Reads in light curve data from file(s).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            If a single file (of any time) is to be read from, the path can be\n",
    "            given using this kwarg. \n",
    "        directory : str\n",
    "            A directory can be given instead of an explicit list of files. The\n",
    "            child class will load all appropriate files in this directory.\n",
    "        list_of_files : list\n",
    "            Instead of the above, a list of files to be loaded can be\n",
    "            explicitly given.\n",
    "        output_dir : str\n",
    "            The directory to save the log file and all outputs to. Defaults to\n",
    "            './' \n",
    "        \n",
    "        data_dict: Dictionary\n",
    "                It a dictionary with index of the column names corresponding to the \n",
    "                following specific keys: ('time','mag','mag_err','flux','flux_err','filters')\n",
    "                \n",
    "                e.g {'time':1,'mag':2}, were 1 and 2 are column index correpoding to \n",
    "                'time' and 'mag' in the input data .\n",
    "                \n",
    "                The user can also provide a list of indices for the 'mag' and 'flux' columns. This is the\n",
    "                case were the brightness is recorded in more than one column.\n",
    "                \n",
    "                e.g {'time':1,'mag':[2,3]} 2 and 3 corresponds to columns with brightness records\n",
    "        \n",
    "        header_nrows: int\n",
    "                The number of rows the header covers in the dataset, by \n",
    "                default 1\n",
    "                \n",
    "         delim_whitespace: bool\n",
    "                Should be True if the data is not separated by a comma, by\n",
    "                default False\n",
    "                \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "#         super().__init__(data_dict,header_nrows=1,delim_whitespace =False,**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "        self.data_type = 'light_curve'\n",
    "        self.metadata = pd.DataFrame(data=[])\n",
    "        \n",
    "\n",
    "        ##### need to understand this line of code!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # ids = [f.split(os.sep)[-1] for f in self.files]\n",
    "        # self.metadata = pd.DataFrame({'filepath': self.files}, index=ids)\n",
    "\n",
    "        \n",
    "\n",
    "        self.data_dict = data_dict\n",
    "        self.header_nrows = header_nrows\n",
    "        self.delim_whitespace = delim_whitespace\n",
    "        self.files = files\n",
    "     \n",
    "        \n",
    "#         ========================================================================================\n",
    "                                   \n",
    "                                    # Reading the light curve data \n",
    "        \n",
    "#         ========================================================================================\n",
    "\n",
    "#     @staticmethod\n",
    "#     def read_lc_from_file(self,flpath):\n",
    "\n",
    "        \n",
    "        '''Function to read the lc from the data\n",
    "        \n",
    "        Input:\n",
    "        flpath: the location of the file\n",
    "        \n",
    "    \n",
    "                \n",
    "        Output:\n",
    "       standardized pandas dataframe with lc data'''\n",
    "        \n",
    "        \n",
    "        # Reading-in the data\n",
    "        \n",
    "        \n",
    "        concat_data_dict = {}\n",
    "        \n",
    "        \n",
    "        # =======Need to fix this so that it concatinates data from multiple files==========================\n",
    "        for obj in range(len(self.files)):\n",
    "            \n",
    "            data = pd.read_csv(self.files[obj],skiprows=self.header_nrows,delim_whitespace=self.delim_whitespace,header=None)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # ==================Magnitudes==================================\n",
    "        # ==============================================================\n",
    "        ID = data.iloc[:,self.data_dict['id']]\n",
    "        time = data.iloc[:,self.data_dict['time']]\n",
    "        \n",
    "        standard_data = {'ID':ID,'time':time}\n",
    "        if 'mag' in self.data_dict.keys(): \n",
    "            \n",
    "            \n",
    "            # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            try:\n",
    "                \n",
    "                \n",
    "        \n",
    "                for i in range(len(self.data_dict['mag'])):\n",
    "                    \n",
    "                    \n",
    "                    # Separatting the columns as per input dictionary\n",
    "    #             \n",
    "\n",
    "                    # Case where there are brightness error columns\n",
    "                    if 'mag_err' in self.data_dict.keys():                \n",
    "\n",
    "                        mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "                        # Creating a new dictionary for the columns above separate data\n",
    "                        standard_data.update({'mag'+str(i):data.iloc[:,self.data_dict['mag'][i]],'mag_error':mag_error})\n",
    "\n",
    "                    # Case were there are no error columns\n",
    "                    else:\n",
    "\n",
    "                        standard_data.update({'mag'+str(i+1):data.iloc[:,self.data_dict['mag'][i]]})\n",
    "                    \n",
    "                    \n",
    "            \n",
    "                \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "            except TypeError:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']]; \n",
    "                \n",
    "                if 'mag_err' in self.data_dict.keys():\n",
    "                    \n",
    "                    \n",
    "                    mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data.update({'mag':mag,'mag_error':mag_error})\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    standard_data.update({'mag':mag})\n",
    "                            \n",
    "            \n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            if 'filters'in self.data_dict.keys() and 'mag_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "                mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'mag':mag,'mag_error':mag_error,'filters':filters})\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'mag':mag,'filters':filters})\n",
    "                \n",
    "                \n",
    "                \n",
    "                    \n",
    "                    \n",
    "    #-----------------------------------------------------------------------------------------------------------------                \n",
    "                \n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````      \n",
    "    #============================================Fluxes===============================================================\n",
    "    #=================================================================================================================\n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            \n",
    "                    # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            try:\n",
    "                \n",
    "                \n",
    "        \n",
    "                for i in range(len(self.data_dict['flux'])):\n",
    "                    \n",
    "                    \n",
    "                    # Separatting the columns as per input dictionary\n",
    "    #             \n",
    "\n",
    "                    # Case where there are brightness error columns\n",
    "                    if 'flux_err' in self.data_dict.keys():                \n",
    "\n",
    "                        flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "                        # Creating a new dictionary for the columns above separate data\n",
    "                        standard_data.update({'flux'+str(i):data.iloc[:,self.data_dict['flux'][i]],'flux_error':flux_error})\n",
    "\n",
    "                    # Case were there are no error columns\n",
    "                    else:\n",
    "\n",
    "                        standard_data.update({'flux'+str(i+1):data.iloc[:,self.data_dict['flux'][i]]})\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            except TypeError:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']]; \n",
    "\n",
    "                if 'flux_err' in self.data_dict.keys():\n",
    "\n",
    "\n",
    "                    flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data.update({'flux':flux,'flux_error':flux_error})\n",
    "\n",
    "                else:\n",
    "\n",
    "                    standard_data.update({'flux':flux})\n",
    "\n",
    "\n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            if 'filters'in self.data_dict.keys() and 'flux_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "                flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'flux':flux,'flux_error':flux_error,'filters':filters})\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'flux':flux,'filters':filters})\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "          \n",
    "            \n",
    "        ids = np.unique(standard_data['ID'])   \n",
    "        self.metadata = pd.DataFrame({'ID': ids}, index=ids)\n",
    "        self.light_curves_data = pd.DataFrame.from_dict(standard_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def get_display_data(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single instance of the dataset in a form that is ready to be\n",
    "        displayed by the web front end.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : str\n",
    "            Index (should be a string to avoid ambiguity)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            json-compatible dictionary of the light curve data\n",
    "        \"\"\"\n",
    "        # print(id)\n",
    "        # ***** Need to extend this to deal with other bands\n",
    "#         time_col = 'time'\n",
    "\n",
    "        # All the standard columns are included here\n",
    "        data_col = ['time','mag','flux','mag1','mag2','flux1','flux2','filters']\n",
    "\n",
    "        err_col = ['mag_error','flux_error']\n",
    "\n",
    "        out_dict = {}\n",
    "\n",
    "#         metadata = self.metadata\n",
    "\n",
    "        ##### need to understand this line of code!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # flpath = metadata[idx]['filepath'].iloc[0]\n",
    "\n",
    "        try:\n",
    "\n",
    "            \n",
    "            # Reading in the light curve data\n",
    "#             light_curve = self.read_lc_from_file(flpath)\n",
    "            light_curve = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "            \n",
    "            # Data and error index \n",
    "            data_indx = [cl for cl in data_col if cl in light_curve.columns.values.tolist()] \n",
    "            err_indx = [cl for cl in err_col if cl in light_curve.columns.values.tolist()]\n",
    "\n",
    "            \n",
    "            # Getting both the data and error columns as per index\n",
    "            out_dict['data'] = light_curve[data_indx].values.tolist()\n",
    "            \n",
    "            \n",
    "            # Returns true if we have error columns\n",
    "            if err_col[0] in light_curve.columns.values.tolist() or err_col[1] in light_curve.columns.values.tolist():\n",
    "                lc_errs = light_curve[err_indx]\n",
    "                out_dict['errors'] = lc_errs.values.tolist()\n",
    "                \n",
    "             \n",
    "\n",
    "                \n",
    "\n",
    "        except (pd.errors.ParserError, pd.errors.EmptyDataError, FileNotFoundError) as e:\n",
    "            print('Error parsing file', flpath)\n",
    "            print('Error message:')\n",
    "            print(e)\n",
    "            out_dict = {'data': [], 'errors': []}\n",
    "\n",
    "        return out_dict\n",
    "    \n",
    "\n",
    "    def get_sample(self,idx):\n",
    "        \n",
    "        \n",
    "        # All the standard columns for feature extraction \n",
    "        data_col = ['time','mag','flux','mag1','mag2','flux1','flux2','mag_error','flux_error']\n",
    "\n",
    "\n",
    "    \n",
    "        metadata = self.metadata\n",
    "\n",
    "        ##### need to understand this line of code!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "        # flpath = metadata[idx]['filepath'].iloc[0]\n",
    "\n",
    "        # empty pandas dataframe to update as per data_col\n",
    "        out_data = pd.DataFrame({})\n",
    "        try:\n",
    "\n",
    "            \n",
    "            # Reading in the light curve data\n",
    "#             light_curve = self.read_lc_from_file(flpath)\n",
    "            \n",
    "            # Choosing light curve values for a specific ID\n",
    "            light_curve = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "            \n",
    "            \n",
    "            sample_data = []\n",
    "            # Getting the columns that correspond to lc columns \n",
    "            for cl in data_col:\n",
    "                \n",
    "                if cl in light_curve.columns.values.tolist():\n",
    "\n",
    "                    out_data[cl] = light_curve[cl].values.tolist()\n",
    "                    sample_data.append(out_data[cl])\n",
    "            \n",
    "                \n",
    "            return sample_data\n",
    "                \n",
    "             \n",
    "\n",
    "                \n",
    "\n",
    "        except (pd.errors.ParserError, pd.errors.EmptyDataError, FileNotFoundError) as e:\n",
    "            print('Error parsing file', flpath)\n",
    "            print('Error message:')\n",
    "            print(e)\n",
    "            out_dict = {'data': [], 'errors': []}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>time</th>\n",
       "      <th>flux1</th>\n",
       "      <th>flux2</th>\n",
       "      <th>flux3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>59798.3205</td>\n",
       "      <td>13</td>\n",
       "      <td>59798.3205</td>\n",
       "      <td>59798.3205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>59798.3281</td>\n",
       "      <td>13</td>\n",
       "      <td>59798.3281</td>\n",
       "      <td>59798.3281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>59798.3357</td>\n",
       "      <td>13</td>\n",
       "      <td>59798.3357</td>\n",
       "      <td>59798.3357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>59798.3466</td>\n",
       "      <td>13</td>\n",
       "      <td>59798.3466</td>\n",
       "      <td>59798.3466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>59798.3576</td>\n",
       "      <td>13</td>\n",
       "      <td>59798.3576</td>\n",
       "      <td>59798.3576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855953</th>\n",
       "      <td>342868</td>\n",
       "      <td>60434.0005</td>\n",
       "      <td>342868</td>\n",
       "      <td>60434.0005</td>\n",
       "      <td>60434.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855954</th>\n",
       "      <td>342868</td>\n",
       "      <td>60434.0115</td>\n",
       "      <td>342868</td>\n",
       "      <td>60434.0115</td>\n",
       "      <td>60434.0115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855955</th>\n",
       "      <td>342868</td>\n",
       "      <td>60434.0224</td>\n",
       "      <td>342868</td>\n",
       "      <td>60434.0224</td>\n",
       "      <td>60434.0224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855956</th>\n",
       "      <td>342868</td>\n",
       "      <td>60435.9857</td>\n",
       "      <td>342868</td>\n",
       "      <td>60435.9857</td>\n",
       "      <td>60435.9857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855957</th>\n",
       "      <td>342868</td>\n",
       "      <td>60436.9840</td>\n",
       "      <td>342868</td>\n",
       "      <td>60436.9840</td>\n",
       "      <td>60436.9840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10855958 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID        time   flux1       flux2       flux3\n",
       "0             13  59798.3205      13  59798.3205  59798.3205\n",
       "1             13  59798.3281      13  59798.3281  59798.3281\n",
       "2             13  59798.3357      13  59798.3357  59798.3357\n",
       "3             13  59798.3466      13  59798.3466  59798.3466\n",
       "4             13  59798.3576      13  59798.3576  59798.3576\n",
       "...          ...         ...     ...         ...         ...\n",
       "10855953  342868  60434.0005  342868  60434.0005  60434.0005\n",
       "10855954  342868  60434.0115  342868  60434.0115  60434.0115\n",
       "10855955  342868  60434.0224  342868  60434.0224  60434.0224\n",
       "10855956  342868  60435.9857  342868  60435.9857  60435.9857\n",
       "10855957  342868  60436.9840  342868  60436.9840  60436.9840\n",
       "\n",
       "[10855958 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2 = ['/home/malema/Desktop/Malema_UWC_Work/Data/test_set_batch1.csv']\n",
    "         \n",
    "#          ,'/home/malema/Desktop/Malema_UWC_Work/Data/test_set_batch1.csv']\n",
    "\n",
    "md = LightCurveDataset(data_dict={'time':1,'flux':[0,1,1],'id':0},files=path2,\n",
    "                     delim_whitespace=False,header_nrows=1)\n",
    "\n",
    "\n",
    "\n",
    "dsp = md.get_display_data(idx=342868)\n",
    " \n",
    "# lc[lc['Id']==40]\n",
    "\n",
    "md.light_curves_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing if get_sample works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feets\n",
    "\n",
    "# The features from the light curves\n",
    "fs = feets.FeatureSpace(\n",
    "\n",
    "    only=['StructureFunction_index_21','Mean','AndersonDarling','Amplitude','Freq1_harmonics_rel_phase_1',\n",
    "          'MaxSlope','LinearTrend','Beyond1Std','CAR_sigma','Period_fit','SlottedA_length',\n",
    "          'SmallKurtosis','Autocor_length','Con','Eta_e'] ) \n",
    "\n",
    "lc = dsp\n",
    "features, values = fs.extract(*lc)\n",
    "val = values.tolist()\n",
    "\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [1,2,3,50]\n",
    "metadata = pd.DataFrame({'filepath': files}, index=[20,2,3,50])\n",
    "flpath = metadata['filepath'].iloc[3]\n",
    "# metadata.keys()\n",
    "\n",
    "flpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.iloc[0].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metadata)\n",
    "\n",
    "dt = pd.read_csv(path2)\n",
    "\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1 = pd.DataFrame({'time':dt.mjd,'flux':dt.flux, 'flux_err':dt.flux_err }, index=dt.object_id.values)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1.loc[13,'time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridget = {'Bridget':'Malema loves you big time','height':'100m', 'smile':'sexy', 'polo':'none'}\n",
    "\n",
    "bridget['Nose'] = 'big'\n",
    "\n",
    "bridget['Bridget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0,1,50)\n",
    "\n",
    "y = np.sin(x)\n",
    "\n",
    "\n",
    "plt.plot(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrition = {'food':['mango','banana','pap','eggs'],'kcal':[10,30,80,100],'kJ':np.array([90,30,10,5])}\n",
    " \n",
    "nutrition['kJ'] = nutrition['kJ'] + 10\n",
    "\n",
    "nutrition = pd.DataFrame.from_dict(nutrition)\n",
    "\n",
    "nutrition\n",
    "\n",
    "for kj in nutrition['food']:\n",
    "    \n",
    "    print(kj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(nutrition.kcal,nutrition.kJ,'*r')\n",
    "plt.xlabel('kcal')\n",
    "plt.ylabel('kJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictn = {}\n",
    "dictn1 = {}\n",
    "\n",
    "fl1 = [1,2,3]\n",
    "fl2 = [4,6,1]\n",
    "fl3 = [20,4,5]\n",
    "fl4 = [0,0,0]\n",
    "\n",
    "dct = {'fl3':fl4}\n",
    "# dct = pd.DataFrame.from_dict(dct)\n",
    "\n",
    "\n",
    "files = [fl1,fl2,fl3]\n",
    "files2 = [fl1,fl2,fl3]\n",
    "\n",
    "for fls in range(len(files)):\n",
    "    \n",
    "    dictn['fl'+str(fls)] = files[fls]\n",
    "\n",
    "dt = pd.DataFrame.from_dict(dictn)\n",
    "    \n",
    "for fls in range(len(files2)):\n",
    "    \n",
    "    dictn1['fl'+str(fls)] = files2[fls]\n",
    "    \n",
    "dt1 = pd.DataFrame.from_dict(dictn1) \n",
    "\n",
    "dt1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'malema'+'brigdet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([dt,dt1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dct['dt','ft','gt'] = [1,1,1],[2,2,2],[3,3,3]\n",
    "\n",
    "dictn = {}\n",
    "dct = {'fl3':fl4}\n",
    "\n",
    "\n",
    "dct.update({'dt':[1,1,1],'ft':[2,2,2],'gt':[3,3,3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3])\n",
    "\n",
    "\n",
    "for i in range(len(x)):\n",
    "    \n",
    "    x[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_columns = [1,2,3]\n",
    "\n",
    "mags = {}\n",
    "\n",
    "cl = np.zeros(len(mag_columns))\n",
    "\n",
    "for i in range(len(mag_columns)):\n",
    "    \n",
    "#     cl[i] = mag_columns[i]\n",
    "    \n",
    "    mags['mag'+str(i)] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mag0': 0, 'mag1': 1, 'mag2': 2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
