{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "# from astronomaly.base.base_dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-51ffb2311c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLightCurveDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader_nrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelim_whitespace\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "# from astronomaly.base.base_dataset import Dataset\n",
    "\n",
    "\n",
    "class LightCurveDataset(Dataset):\n",
    "    def __init__(self,data_dict,header_nrows=1,delim_whitespace =False,**kwargs):\n",
    "        \"\"\"\n",
    "        Reads in light curve data from file(s).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            If a single file (of any time) is to be read from, the path can be\n",
    "            given using this kwarg. \n",
    "        directory : str\n",
    "            A directory can be given instead of an explicit list of files. The\n",
    "            child class will load all appropriate files in this directory.\n",
    "        list_of_files : list\n",
    "            Instead of the above, a list of files to be loaded can be\n",
    "            explicitly given.\n",
    "        output_dir : str\n",
    "            The directory to save the log file and all outputs to. Defaults to\n",
    "            './' \n",
    "        \n",
    "        data_dict: Dictionary\n",
    "                It a dictionary with index of the column names corresponding to the \n",
    "                following specific keys: ('time','mag','mag_err','flux','flux_err','filters')\n",
    "                \n",
    "                e.g {'time':1,'mag':2}, were 1 and 2 are column index correpoding to \n",
    "                'time' and 'mag' in the input data \n",
    "        \n",
    "        header_nrows: int\n",
    "                The number of rows the header covers in the dataset, by \n",
    "                default 1\n",
    "                \n",
    "         delim_whitespace: bool\n",
    "                Should be True if the data is not separated by a comma, by\n",
    "                default False\n",
    "                \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(data_dict,header_nrows=1,delim_whitespace =False,**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "        self.data_type = 'light_curve'\n",
    "        self.metadata = pd.DataFrame(data=[])\n",
    "        \n",
    "\n",
    "        ##### need to understand this line of code!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # ids = [f.split(os.sep)[-1] for f in self.files]\n",
    "        # self.metadata = pd.DataFrame({'filepath': self.files}, index=ids)\n",
    "\n",
    "        \n",
    "\n",
    "        self.data_dict = data_dict\n",
    "        self.header_nrows = header_nrows\n",
    "        self.delim_whitespace = delim_whitespace\n",
    "     \n",
    "        \n",
    "#         ========================================================================================\n",
    "                                   \n",
    "                                    # Reading the light curve data \n",
    "        \n",
    "#         ========================================================================================\n",
    "\n",
    "        \n",
    "        \n",
    "        # Reading-in the data\n",
    "        \n",
    "        \n",
    "        \n",
    "        # ===================Case for multiple files of light curve data================================\n",
    "        try:\n",
    "\n",
    "            data=pd.concat([pd.read_csv(self.files[0],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None),\n",
    "                               \n",
    "                               pd.read_csv(self.files[1],skiprows=self.header_nrows,\n",
    "                                           delim_whitespace=self.delim_whitespace,header=None)])\n",
    "            \n",
    "            \n",
    "\n",
    "            for fl in range(2,len(self.files)):\n",
    "\n",
    "                data=pd.concat([data, pd.read_csv(self.files[fl],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None)])\n",
    "                \n",
    "        \n",
    "        # ===================Case for single file of light curve data==================================\n",
    "        except IndexError:\n",
    "            \n",
    "            \n",
    "            data = pd.read_csv(self.files[0],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None)\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        # ==================Magnitudes==================================\n",
    "        # ==============================================================\n",
    "        Id = data.iloc[:,self.data_dict['id']]\n",
    "        time = data.iloc[:,self.data_dict['time']]\n",
    "        \n",
    "        standard_data = {'ID':Id,'time':time}\n",
    "        \n",
    "        if 'mag' in self.data_dict.keys(): \n",
    "            \n",
    "            \n",
    "            # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            try:\n",
    "                \n",
    "                \n",
    "        \n",
    "                for i in range(len(self.data_dict['mag'])):\n",
    "                    \n",
    "                    \n",
    "                    # Separatting the columns as per input dictionary\n",
    "    #             \n",
    "\n",
    "                    # Case where there are brightness error columns\n",
    "                    if 'mag_err' in self.data_dict.keys():                \n",
    "\n",
    "                        # Creating a new dictionary for the columns above separate data\n",
    "                        standard_data.update({'mag'+str(i+1):data.iloc[:,self.data_dict['mag'][i]],\n",
    "                                              'mag_error'+str(i+1):data.iloc[:,self.data_dict['mag_err'][i]]})\n",
    "\n",
    "                    # Case were there are no error columns\n",
    "                    else:\n",
    "\n",
    "                        standard_data.update({'mag'+str(i+1):data.iloc[:,self.data_dict['mag'][i]]})\n",
    "                    \n",
    "                    \n",
    "            \n",
    "                \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "            except TypeError:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']]; \n",
    "                \n",
    "                if 'mag_err' in self.data_dict.keys():\n",
    "                    \n",
    "                    \n",
    "                    mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data.update({'mag':mag,'mag_error':mag_error})\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    standard_data.update({'mag':mag})\n",
    "                            \n",
    "            \n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            if 'filters'in self.data_dict.keys() and 'mag_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "                mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'mag':mag,'mag_error':mag_error,'filters':filters})\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'mag':mag,'filters':filters})\n",
    "                \n",
    "                \n",
    "                \n",
    "                    \n",
    "                    \n",
    "    #-----------------------------------------------------------------------------------------------------------------                \n",
    "                \n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````      \n",
    "    #============================================Fluxes===============================================================\n",
    "    #=================================================================================================================\n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            \n",
    "                    # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            try:\n",
    "                \n",
    "                \n",
    "        \n",
    "                for i in range(len(self.data_dict['flux'])):\n",
    "                    \n",
    "                    \n",
    "                    # Separatting the columns as per input dictionary\n",
    "    #             \n",
    "\n",
    "                    # Case where there are brightness error columns\n",
    "                    if 'flux_err' in self.data_dict.keys():                \n",
    "\n",
    "                        # Creating a new dictionary for the columns above separate data\n",
    "                        standard_data.update({'flux'+str(i+1):data.iloc[:,self.data_dict['flux'][i]],\n",
    "                                              'flux_error'+str(i+1):data.iloc[:,self.data_dict['flux_err'][i]]})\n",
    "                    # Case were there are no error columns\n",
    "                    else:\n",
    "\n",
    "                        standard_data.update({'flux'+str(i+1):data.iloc[:,self.data_dict['flux'][i]]})\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            except TypeError:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']]; \n",
    "\n",
    "                if 'flux_err' in self.data_dict.keys():\n",
    "\n",
    "\n",
    "                    flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data.update({'flux':flux,'flux_error':flux_error})\n",
    "\n",
    "                else:\n",
    "\n",
    "                    standard_data.update({'flux':flux})\n",
    "\n",
    "\n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            if 'filters'in self.data_dict.keys() and 'flux_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "                flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'flux':flux,'flux_error':flux_error,'filters':filters})\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'flux':flux,'filters':filters})\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "          \n",
    "            \n",
    "        ids = np.unique(standard_data['ID'])   \n",
    "        self.metadata = pd.DataFrame({'ID': ids}, index=ids)\n",
    "        self.light_curves_data = pd.DataFrame.from_dict(standard_data)\n",
    "    \n",
    "    def get_display_data(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single instance of the dataset in a form that is ready to be\n",
    "        displayed by the web front end.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : str\n",
    "            Index (should be a string to avoid ambiguity)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            json-compatible dictionary of the light curve data\n",
    "        \"\"\"\n",
    "        # print(id)\n",
    "        # ***** Need to extend this to deal with other bands\n",
    "#         time_col = 'time'\n",
    "\n",
    "        # All the standard columns are included here\n",
    "        data_col = ['time','mag','flux','mag1','mag2','flux1','flux2','filters']\n",
    "\n",
    "        err_col = ['mag_error','flux_error']\n",
    "\n",
    "        out_dict = {}\n",
    "\n",
    "#         metadata = self.metadata\n",
    "\n",
    "        ##### need to understand this line of code!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # flpath = metadata[idx]['filepath'].iloc[0]\n",
    "\n",
    "        try:\n",
    "\n",
    "            \n",
    "            # Reading in the light curve data\n",
    "#             light_curve = self.read_lc_from_file(flpath)\n",
    "            light_curve = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "            \n",
    "            # Data and error index \n",
    "            data_indx = [cl for cl in data_col if cl in light_curve.columns.values.tolist()] \n",
    "            err_indx = [cl for cl in err_col if cl in light_curve.columns.values.tolist()]\n",
    "\n",
    "            \n",
    "            # Getting both the data and error columns as per index\n",
    "            out_dict['data'] = light_curve[data_indx].values.tolist()\n",
    "            \n",
    "            \n",
    "            # Returns true if we have error columns\n",
    "            if err_col[0] in light_curve.columns.values.tolist() or err_col[1] in light_curve.columns.values.tolist():\n",
    "                lc_errs = light_curve[err_indx]\n",
    "                out_dict['errors'] = lc_errs.values.tolist()\n",
    "                \n",
    "             \n",
    "\n",
    "                \n",
    "\n",
    "        except (pd.errors.ParserError, pd.errors.EmptyDataError, FileNotFoundError) as e:\n",
    "            print('Error parsing file', flpath)\n",
    "            print('Error message:')\n",
    "            print(e)\n",
    "            out_dict = {'data': [], 'errors': []}\n",
    "\n",
    "        return out_dict\n",
    "    \n",
    "\n",
    "    def get_sample(self,idx):\n",
    "        \n",
    "        \n",
    "        # All the standard columns for feature extraction \n",
    "        data_col = ['time','mag','flux','mag1','mag2','flux1','flux2','mag_error','flux_error']\n",
    "\n",
    "\n",
    "    \n",
    "        metadata = self.metadata\n",
    "\n",
    "        ##### need to understand this line of code!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "        # flpath = metadata[idx]['filepath'].iloc[0]\n",
    "\n",
    "        # empty pandas dataframe to update as per data_col\n",
    "        out_data = pd.DataFrame({})\n",
    "        try:\n",
    "\n",
    "            \n",
    "            # Reading in the light curve data\n",
    "#             light_curve = self.read_lc_from_file(flpath)\n",
    "            \n",
    "            # Choosing light curve values for a specific ID\n",
    "            light_curve = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "            \n",
    "            \n",
    "            sample_data = []\n",
    "            # Getting the columns that correspond to lc columns \n",
    "            for cl in data_col:\n",
    "                \n",
    "                if cl in light_curve.columns.values.tolist():\n",
    "\n",
    "                    out_data[cl] = light_curve[cl].values.tolist()\n",
    "                    sample_data.append(out_data[cl])\n",
    "            \n",
    "                \n",
    "            return sample_data\n",
    "                \n",
    "             \n",
    "\n",
    "                \n",
    "\n",
    "        except (pd.errors.ParserError, pd.errors.EmptyDataError, FileNotFoundError) as e:\n",
    "            print('Error parsing file', flpath)\n",
    "            print('Error message:')\n",
    "            print(e)\n",
    "            out_dict = {'data': [], 'errors': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "# from astronomaly.base.base_dataset import Dataset\n",
    "\n",
    "\n",
    "class LightCurveDataset(object):\n",
    "    def __init__(self,data_dict,files,header_nrows=1,delim_whitespace =False,**kwargs):\n",
    "        \"\"\"\n",
    "        Reads in light curve data from file(s).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            If a single file (of any time) is to be read from, the path can be\n",
    "            given using this kwarg. \n",
    "        directory : str\n",
    "            A directory can be given instead of an explicit list of files. The\n",
    "            child class will load all appropriate files in this directory.\n",
    "        list_of_files : list\n",
    "            Instead of the above, a list of files to be loaded can be\n",
    "            explicitly given.\n",
    "        output_dir : str\n",
    "            The directory to save the log file and all outputs to. Defaults to\n",
    "            './' \n",
    "        \n",
    "        data_dict: Dictionary\n",
    "                It a dictionary with index of the column names corresponding to the \n",
    "                following specific keys: ('time','mag','mag_err','flux','flux_err','filters')\n",
    "                \n",
    "                e.g {'time':1,'mag':2}, were 1 and 2 are column index correpoding to \n",
    "                'time' and 'mag' in the input data .\n",
    "                \n",
    "                The user can also provide a list of indices for the 'mag' and 'flux' columns. This is the\n",
    "                case were the brightness is recorded in more than one column.\n",
    "                \n",
    "                e.g {'time':1,'mag':[2,3]} 2 and 3 corresponds to columns with brightness records\n",
    "        \n",
    "        header_nrows: int\n",
    "                The number of rows the header covers in the dataset, by \n",
    "                default 1\n",
    "                \n",
    "         delim_whitespace: bool\n",
    "                Should be True if the data is not separated by a comma, by\n",
    "                default False\n",
    "                \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "#         super().__init__(data_dict,header_nrows=1,delim_whitespace =False,**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "        self.data_type = 'light_curve'\n",
    "        self.metadata = pd.DataFrame(data=[])\n",
    "        \n",
    "\n",
    "        ##### need to understand this line of code!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # ids = [f.split(os.sep)[-1] for f in self.files]\n",
    "        # self.metadata = pd.DataFrame({'filepath': self.files}, index=ids)\n",
    "\n",
    "        \n",
    "\n",
    "        self.data_dict = data_dict\n",
    "        self.header_nrows = header_nrows\n",
    "        self.delim_whitespace = delim_whitespace\n",
    "        self.files = files\n",
    "     \n",
    "        \n",
    "#         ========================================================================================\n",
    "                                   \n",
    "                                    # Reading the light curve data \n",
    "        \n",
    "#         ========================================================================================\n",
    "\n",
    "#     @staticmethod\n",
    "#     def read_lc_from_file(self,flpath):\n",
    "\n",
    "        \n",
    "        '''Function to read the lc from the data\n",
    "        \n",
    "        Input:\n",
    "        flpath: the location of the file\n",
    "        \n",
    "    \n",
    "                \n",
    "        Output:\n",
    "       standardized pandas dataframe with lc data'''\n",
    "        \n",
    "        \n",
    "        # Reading-in the data\n",
    "        \n",
    "        \n",
    "        \n",
    "        # ===================Case for multiple files of light curve data================================\n",
    "        try:\n",
    "\n",
    "            data=pd.concat([pd.read_csv(self.files[0],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None),\n",
    "                               \n",
    "                               pd.read_csv(self.files[1],skiprows=self.header_nrows,\n",
    "                                           delim_whitespace=self.delim_whitespace,header=None)])\n",
    "            \n",
    "            \n",
    "\n",
    "            for fl in range(2,len(self.files)):\n",
    "\n",
    "                data=pd.concat([data, pd.read_csv(self.files[fl],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None)])\n",
    "                \n",
    "        \n",
    "        # ===================Case for single file of light curve data==================================\n",
    "        except IndexError:\n",
    "            \n",
    "            \n",
    "            data = pd.read_csv(self.files[0],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None)\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # ==================Magnitudes==================================\n",
    "        # ==============================================================\n",
    "        ID = data.iloc[:,self.data_dict['id']]\n",
    "        time = data.iloc[:,self.data_dict['time']]\n",
    "        \n",
    "        standard_data = {'ID':ID,'time':time}\n",
    "        if 'mag' in self.data_dict.keys(): \n",
    "            \n",
    "            \n",
    "            # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            try:\n",
    "                \n",
    "                \n",
    "        \n",
    "                for i in range(len(self.data_dict['mag'])):\n",
    "                    \n",
    "                    \n",
    "                    # Separatting the columns as per input dictionary\n",
    "    #             \n",
    "\n",
    "                    # Case where there are brightness error columns\n",
    "                    if 'mag_err' in self.data_dict.keys():                \n",
    "\n",
    "#                         mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "                        # Creating a new dictionary for the columns above separate data\n",
    "                        standard_data.update({'mag'+str(i+1):data.iloc[:,self.data_dict['mag'][i]],\n",
    "                                              'mag_error'+str(i+1):data.iloc[:,self.data_dict['mag_err'][i]]})\n",
    "                    # Case were there are no error columns\n",
    "                    else:\n",
    "\n",
    "                        standard_data.update({'mag'+str(i+1):data.iloc[:,self.data_dict['mag'][i]]})\n",
    "                    \n",
    "                    \n",
    "            \n",
    "                \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "            except TypeError:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']]; \n",
    "                \n",
    "                if 'mag_err' in self.data_dict.keys():\n",
    "                    \n",
    "                    \n",
    "                    mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data.update({'mag':mag,'mag_error':mag_error})\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    standard_data.update({'mag':mag})\n",
    "                            \n",
    "            \n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            if 'filters'in self.data_dict.keys() and 'mag_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "                mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'mag':mag,'mag_error':mag_error,'filters':filters})\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'mag':mag,'filters':filters})\n",
    "                \n",
    "                \n",
    "                \n",
    "                    \n",
    "                    \n",
    "    #-----------------------------------------------------------------------------------------------------------------                \n",
    "                \n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````      \n",
    "    #============================================Fluxes===============================================================\n",
    "    #=================================================================================================================\n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            \n",
    "                    # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            try:\n",
    "                \n",
    "                \n",
    "        \n",
    "                for i in range(len(self.data_dict['flux'])):\n",
    "                    \n",
    "                    \n",
    "                    # Separatting the columns as per input dictionary\n",
    "    #             \n",
    "\n",
    "                    # Case where there are brightness error columns\n",
    "                    if 'flux_err' in self.data_dict.keys():                \n",
    "\n",
    "                        flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "                        # Creating a new dictionary for the columns above separate data\n",
    "                        standard_data.update({'flux'+str(i+1):data.iloc[:,self.data_dict['flux'][i]],\n",
    "                                              'flux_error'+str(i+1):data.iloc[:,self.data_dict['flux_err'][i]]})\n",
    "                    # Case were there are no error columns\n",
    "                    else:\n",
    "\n",
    "                        standard_data.update({'flux'+str(i+1):data.iloc[:,self.data_dict['flux'][i]]})\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            except TypeError:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']]; \n",
    "\n",
    "                if 'flux_err' in self.data_dict.keys():\n",
    "\n",
    "\n",
    "                    flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data.update({'flux':flux,'flux_error':flux_error})\n",
    "\n",
    "                else:\n",
    "\n",
    "                    standard_data.update({'flux':flux})\n",
    "\n",
    "\n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            if 'filters'in self.data_dict.keys() and 'flux_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "                flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'flux':flux,'flux_error':flux_error,'filters':filters})\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'flux':flux,'filters':filters})\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "          \n",
    "            \n",
    "        ids = np.unique(standard_data['ID'])   \n",
    "        self.metadata = pd.DataFrame({'ID': ids}, index=ids)\n",
    "        self.light_curves_data = pd.DataFrame.from_dict(standard_data)\n",
    "    \n",
    "    def get_display_data(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single instance of the dataset in a form that is ready to be\n",
    "        displayed by the web front end.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : str\n",
    "            Index (should be a string to avoid ambiguity)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            json-compatible dictionary of the light curve data\n",
    "        \"\"\"\n",
    "        # print(id)\n",
    "        # ***** Need to extend this to deal with other bands\n",
    "#         time_col = 'time'\n",
    "\n",
    "        # All the standard columns are included here\n",
    "        data_col = ['time','mag','flux','mag1','mag2','flux1','flux2','filters']\n",
    "\n",
    "        err_col = ['mag_error','flux_error']\n",
    "\n",
    "        out_dict = {}\n",
    "\n",
    "#         metadata = self.metadata\n",
    "\n",
    "        ##### need to understand this line of code!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # flpath = metadata[idx]['filepath'].iloc[0]\n",
    "\n",
    "        try:\n",
    "\n",
    "            \n",
    "            # Reading in the light curve data\n",
    "#             light_curve = self.read_lc_from_file(flpath)\n",
    "            light_curve = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "            \n",
    "            # Data and error index \n",
    "            data_indx = [cl for cl in data_col if cl in light_curve.columns.values.tolist()] \n",
    "            err_indx = [cl for cl in err_col if cl in light_curve.columns.values.tolist()]\n",
    "\n",
    "            \n",
    "            # Getting both the data and error columns as per index\n",
    "            out_dict['data'] = light_curve[data_indx].values.tolist()\n",
    "            \n",
    "            \n",
    "            # Returns true if we have error columns\n",
    "            if err_col[0] in light_curve.columns.values.tolist() or err_col[1] in light_curve.columns.values.tolist():\n",
    "                lc_errs = light_curve[err_indx]\n",
    "                out_dict['errors'] = lc_errs.values.tolist()\n",
    "                \n",
    "             \n",
    "\n",
    "                \n",
    "\n",
    "        except (pd.errors.ParserError, pd.errors.EmptyDataError, FileNotFoundError) as e:\n",
    "            print('Error parsing file', flpath)\n",
    "            print('Error message:')\n",
    "            print(e)\n",
    "            out_dict = {'data': [], 'errors': []}\n",
    "\n",
    "        return out_dict\n",
    "    \n",
    "\n",
    "    def get_sample(self,idx):\n",
    "        \n",
    "        \n",
    "        # All the standard columns for feature extraction \n",
    "        data_col = ['time','mag','flux','mag1','mag2','flux1','flux2','mag_error','flux_error']\n",
    "\n",
    "\n",
    "    \n",
    "        metadata = self.metadata\n",
    "\n",
    "        ##### need to understand this line of code!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "        # flpath = metadata[idx]['filepath'].iloc[0]\n",
    "\n",
    "        # empty pandas dataframe to update as per data_col\n",
    "        out_data = pd.DataFrame({})\n",
    "        try:\n",
    "\n",
    "            \n",
    "            # Reading in the light curve data\n",
    "#             light_curve = self.read_lc_from_file(flpath)\n",
    "            \n",
    "            # Choosing light curve values for a specific ID\n",
    "            light_curve = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "            \n",
    "            \n",
    "            sample_data = []\n",
    "            # Getting the columns that correspond to lc columns \n",
    "            for cl in data_col:\n",
    "                \n",
    "                if cl in light_curve.columns.values.tolist():\n",
    "\n",
    "                    out_data[cl] = light_curve[cl].values.tolist()\n",
    "                    sample_data.append(out_data[cl])\n",
    "            \n",
    "                \n",
    "            return sample_data\n",
    "                \n",
    "             \n",
    "\n",
    "                \n",
    "\n",
    "        except (pd.errors.ParserError, pd.errors.EmptyDataError, FileNotFoundError) as e:\n",
    "            print('Error parsing file', flpath)\n",
    "            print('Error message:')\n",
    "            print(e)\n",
    "            out_dict = {'data': [], 'errors': []}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>time</th>\n",
       "      <th>mag1</th>\n",
       "      <th>mag_error1</th>\n",
       "      <th>mag2</th>\n",
       "      <th>mag_error2</th>\n",
       "      <th>mag3</th>\n",
       "      <th>mag_error3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>59798.3205</td>\n",
       "      <td>13</td>\n",
       "      <td>59798.3205</td>\n",
       "      <td>59798.3205</td>\n",
       "      <td>2</td>\n",
       "      <td>59798.3205</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>59798.3281</td>\n",
       "      <td>13</td>\n",
       "      <td>59798.3281</td>\n",
       "      <td>59798.3281</td>\n",
       "      <td>1</td>\n",
       "      <td>59798.3281</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>59798.3357</td>\n",
       "      <td>13</td>\n",
       "      <td>59798.3357</td>\n",
       "      <td>59798.3357</td>\n",
       "      <td>3</td>\n",
       "      <td>59798.3357</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>59798.3466</td>\n",
       "      <td>13</td>\n",
       "      <td>59798.3466</td>\n",
       "      <td>59798.3466</td>\n",
       "      <td>4</td>\n",
       "      <td>59798.3466</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>59798.3576</td>\n",
       "      <td>13</td>\n",
       "      <td>59798.3576</td>\n",
       "      <td>59798.3576</td>\n",
       "      <td>5</td>\n",
       "      <td>59798.3576</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855953</th>\n",
       "      <td>342868</td>\n",
       "      <td>60434.0005</td>\n",
       "      <td>342868</td>\n",
       "      <td>60434.0005</td>\n",
       "      <td>60434.0005</td>\n",
       "      <td>3</td>\n",
       "      <td>60434.0005</td>\n",
       "      <td>342868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855954</th>\n",
       "      <td>342868</td>\n",
       "      <td>60434.0115</td>\n",
       "      <td>342868</td>\n",
       "      <td>60434.0115</td>\n",
       "      <td>60434.0115</td>\n",
       "      <td>4</td>\n",
       "      <td>60434.0115</td>\n",
       "      <td>342868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855955</th>\n",
       "      <td>342868</td>\n",
       "      <td>60434.0224</td>\n",
       "      <td>342868</td>\n",
       "      <td>60434.0224</td>\n",
       "      <td>60434.0224</td>\n",
       "      <td>5</td>\n",
       "      <td>60434.0224</td>\n",
       "      <td>342868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855956</th>\n",
       "      <td>342868</td>\n",
       "      <td>60435.9857</td>\n",
       "      <td>342868</td>\n",
       "      <td>60435.9857</td>\n",
       "      <td>60435.9857</td>\n",
       "      <td>0</td>\n",
       "      <td>60435.9857</td>\n",
       "      <td>342868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855957</th>\n",
       "      <td>342868</td>\n",
       "      <td>60436.9840</td>\n",
       "      <td>342868</td>\n",
       "      <td>60436.9840</td>\n",
       "      <td>60436.9840</td>\n",
       "      <td>0</td>\n",
       "      <td>60436.9840</td>\n",
       "      <td>342868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32567874 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID        time    mag1  mag_error1        mag2  mag_error2  \\\n",
       "0             13  59798.3205      13  59798.3205  59798.3205           2   \n",
       "1             13  59798.3281      13  59798.3281  59798.3281           1   \n",
       "2             13  59798.3357      13  59798.3357  59798.3357           3   \n",
       "3             13  59798.3466      13  59798.3466  59798.3466           4   \n",
       "4             13  59798.3576      13  59798.3576  59798.3576           5   \n",
       "...          ...         ...     ...         ...         ...         ...   \n",
       "10855953  342868  60434.0005  342868  60434.0005  60434.0005           3   \n",
       "10855954  342868  60434.0115  342868  60434.0115  60434.0115           4   \n",
       "10855955  342868  60434.0224  342868  60434.0224  60434.0224           5   \n",
       "10855956  342868  60435.9857  342868  60435.9857  60435.9857           0   \n",
       "10855957  342868  60436.9840  342868  60436.9840  60436.9840           0   \n",
       "\n",
       "                mag3  mag_error3  \n",
       "0         59798.3205          13  \n",
       "1         59798.3281          13  \n",
       "2         59798.3357          13  \n",
       "3         59798.3466          13  \n",
       "4         59798.3576          13  \n",
       "...              ...         ...  \n",
       "10855953  60434.0005      342868  \n",
       "10855954  60434.0115      342868  \n",
       "10855955  60434.0224      342868  \n",
       "10855956  60435.9857      342868  \n",
       "10855957  60436.9840      342868  \n",
       "\n",
       "[32567874 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2 = ['/home/malema/Desktop/Malema_UWC_Work/Data/test_set_batch1.csv',\n",
    "         '/home/malema/Desktop/Malema_UWC_Work/Data/test_set_batch1.csv',\n",
    "         '/home/malema/Desktop/Malema_UWC_Work/Data/test_set_batch1.csv']\n",
    "         \n",
    "#          ,'/home/malema/Desktop/Malema_UWC_Work/Data/test_set_batch1.csv']\n",
    "\n",
    "md = LightCurveDataset(data_dict={'time':1,'mag':[0,1,1],'mag_err':[1,2,0],'id':0},files=path2,\n",
    "                     delim_whitespace=False,header_nrows=1)\n",
    "\n",
    "\n",
    "\n",
    "dsp = md.get_display_data(idx=342868)\n",
    " \n",
    "# lc[lc['Id']==40]\n",
    "\n",
    "md.light_curves_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32567874"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10855958*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing if get_sample works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malema/anaconda3/lib/python3.8/site-packages/feets/extractors/core.py:234: ExtractorWarning: The original FATS documentation says that the result of AndersonDarling must be ~0.25 for gausian distribution but the  result is ~-0.60\n",
      "  warnings.warn(w, ExtractorWarning)\n"
     ]
    },
    {
     "ename": "DataRequiredError",
     "evalue": "magnitude",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataRequiredError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bb6cac4902c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdsp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/feets/core.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, time, magnitude, error, magnitude2, aligned_time, aligned_magnitude, aligned_magnitude2, aligned_error, aligned_error2)\u001b[0m\n\u001b[1;32m    277\u001b[0m                 aligned_error=None, aligned_error2=None):\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         kwargs = self.dict_data_as_array({\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0mDATA_TIME\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mDATA_MAGNITUDE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/feets/core.py\u001b[0m in \u001b[0;36mdict_data_as_array\u001b[0;34m(self, d)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_required_data\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mDataRequiredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0marray_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marray_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataRequiredError\u001b[0m: magnitude"
     ]
    }
   ],
   "source": [
    "import feets\n",
    "\n",
    "# The features from the light curves\n",
    "fs = feets.FeatureSpace(\n",
    "\n",
    "    only=['StructureFunction_index_21','Mean','AndersonDarling','Amplitude','Freq1_harmonics_rel_phase_1',\n",
    "          'MaxSlope','LinearTrend','Beyond1Std','CAR_sigma','Period_fit','SlottedA_length',\n",
    "          'SmallKurtosis','Autocor_length','Con','Eta_e'] ) \n",
    "\n",
    "lc = dsp\n",
    "features, values = fs.extract(*lc)\n",
    "val = values.tolist()\n",
    "\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [1,2,3,50]\n",
    "metadata = pd.DataFrame({'filepath': files}, index=[20,2,3,50])\n",
    "flpath = metadata['filepath'].iloc[3]\n",
    "# metadata.keys()\n",
    "\n",
    "flpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.iloc[0].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metadata)\n",
    "\n",
    "dt = pd.read_csv(path2)\n",
    "\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt1 = pd.DataFrame({'time':dt.mjd,'flux':dt.flux, 'flux_err':dt.flux_err }, index=dt.object_id.values)\n",
    "\n",
    "dt1 = {'time':[1,2], 'mag':[2,4]}\n",
    "dt2 = {'time':[1,2], 'mag':[1,2]}\n",
    "dt3 = {'time':[2,3], 'mag':[2,3]}\n",
    "dt4 = {'time':[0,0], 'mag':[0,0]}\n",
    "# dt3 = {'time':[2,3], 'mag':[2,3]}\n",
    "\n",
    "\n",
    "dt1 = pd.DataFrame(dt1);dt2 = pd.DataFrame(dt2); dt3 = pd.DataFrame(dt3);dt4 = pd.DataFrame(dt4)\n",
    "\n",
    "# print(dt1)\n",
    "# print(dt2)\n",
    "# print(dt3)\n",
    "\n",
    "lst = [dt1,dt2]\n",
    "try:\n",
    "\n",
    "    new_dat=pd.concat([lst[0],lst[1]])\n",
    "\n",
    "    for i in range(2,len(lst)):\n",
    "\n",
    "        new_dat=pd.concat([new_dat,lst[i]])\n",
    "        \n",
    "except IndexError:\n",
    "    \n",
    "    new_dat = lst[0]\n",
    "\n",
    "new_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1.loc[13,'time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0,1,50)\n",
    "\n",
    "y = np.sin(x)\n",
    "\n",
    "\n",
    "plt.plot(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrition = {'food':['mango','banana','pap','eggs'],'kcal':[10,30,80,100],'kJ':np.array([90,30,10,5])}\n",
    " \n",
    "nutrition['kJ'] = nutrition['kJ'] + 10\n",
    "\n",
    "nutrition = pd.DataFrame.from_dict(nutrition)\n",
    "\n",
    "nutrition\n",
    "\n",
    "for kj in nutrition['food']:\n",
    "    \n",
    "    print(kj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(nutrition.kcal,nutrition.kJ,'*r')\n",
    "plt.xlabel('kcal')\n",
    "plt.ylabel('kJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictn = {}\n",
    "dictn1 = {}\n",
    "\n",
    "fl1 = [1,2,3]\n",
    "fl2 = [4,6,1]\n",
    "fl3 = [20,4,5]\n",
    "fl4 = [0,0,0]\n",
    "\n",
    "dct = {'fl3':fl4}\n",
    "# dct = pd.DataFrame.from_dict(dct)\n",
    "\n",
    "\n",
    "files = [fl1,fl2,fl3]\n",
    "files2 = [fl1,fl2,fl3]\n",
    "\n",
    "for fls in range(len(files)):\n",
    "    \n",
    "    dictn['fl'+str(fls)] = files[fls]\n",
    "\n",
    "dt = pd.DataFrame.from_dict(dictn)\n",
    "    \n",
    "for fls in range(len(files2)):\n",
    "    \n",
    "    dictn1['fl'+str(fls)] = files2[fls]\n",
    "    \n",
    "dt1 = pd.DataFrame.from_dict(dictn1) \n",
    "\n",
    "dt1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'malema'+'brigdet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([dt,dt1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dct['dt','ft','gt'] = [1,1,1],[2,2,2],[3,3,3]\n",
    "\n",
    "dictn = {}\n",
    "dct = {'fl3':fl4}\n",
    "\n",
    "\n",
    "dct.update({'dt':[1,1,1],'ft':[2,2,2],'gt':[3,3,3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3])\n",
    "\n",
    "\n",
    "for i in range(len(x)):\n",
    "    \n",
    "    x[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_columns = [1,2,3]\n",
    "\n",
    "mags = {}\n",
    "\n",
    "cl = np.zeros(len(mag_columns))\n",
    "\n",
    "for i in range(len(mag_columns)):\n",
    "    \n",
    "#     cl[i] = mag_columns[i]\n",
    "    \n",
    "    mags['mag'+str(i)] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
