{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "# from astronomaly.base.base_dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-51ffb2311c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLightCurveDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader_nrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelim_whitespace\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "# from astronomaly.base.base_dataset import Dataset\n",
    "\n",
    "\n",
    "class LightCurveDataset(Dataset):\n",
    "    def __init__(self,data_dict,header_nrows=1,delim_whitespace =False,**kwargs):\n",
    "        \"\"\"\n",
    "        Reads in light curve data from file(s).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            If a single file (of any time) is to be read from, the path can be\n",
    "            given using this kwarg. \n",
    "        directory : str\n",
    "            A directory can be given instead of an explicit list of files. The\n",
    "            child class will load all appropriate files in this directory.\n",
    "        list_of_files : list\n",
    "            Instead of the above, a list of files to be loaded can be\n",
    "            explicitly given.\n",
    "        output_dir : str\n",
    "            The directory to save the log file and all outputs to. Defaults to\n",
    "            './' \n",
    "        \n",
    "        data_dict: Dictionary\n",
    "                It a dictionary with index of the column names corresponding to the \n",
    "                following specific keys: ('time','mag','mag_err','flux','flux_err','filters')\n",
    "                \n",
    "                e.g {'time':1,'mag':2}, were 1 and 2 are column index correpoding to \n",
    "                'time' and 'mag' in the input data \n",
    "                \n",
    "                The user can also provide a list of indices for the 'mag' and 'flux' columns. This is the\n",
    "                case were the brightness is recorded in more than one column.\n",
    "                \n",
    "                e.g {'time':1,'mag':[2,3]} 2 and 3 corresponds to columns with brightness records\n",
    "        \n",
    "        header_nrows: int\n",
    "                The number of rows the header covers in the dataset, by \n",
    "                default 1\n",
    "                \n",
    "         delim_whitespace: bool\n",
    "                Should be True if the data is not separated by a comma, by\n",
    "                default False\n",
    "                \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(data_dict,header_nrows=1,delim_whitespace =False,**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "        self.data_type = 'light_curve'\n",
    "        self.metadata = pd.DataFrame(data=[])\n",
    "        \n",
    "\n",
    "        ##### need to understand this line of code!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # ids = [f.split(os.sep)[-1] for f in self.files]\n",
    "        # self.metadata = pd.DataFrame({'filepath': self.files}, index=ids)\n",
    "\n",
    "        \n",
    "\n",
    "        self.data_dict = data_dict\n",
    "        self.header_nrows = header_nrows\n",
    "        self.delim_whitespace = delim_whitespace\n",
    "     \n",
    "        \n",
    "#         ========================================================================================\n",
    "                                   \n",
    "                                    # Reading the light curve data \n",
    "        \n",
    "#         ========================================================================================\n",
    "\n",
    "        \n",
    "        \n",
    "        # Reading-in the data\n",
    "        \n",
    "        \n",
    "        \n",
    "        # ===================Case for multiple files of light curve data================================\n",
    "        try:\n",
    "\n",
    "            data=pd.concat([pd.read_csv(self.files[0],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None),\n",
    "                               \n",
    "                               pd.read_csv(self.files[1],skiprows=self.header_nrows,\n",
    "                                           delim_whitespace=self.delim_whitespace,header=None)])\n",
    "            \n",
    "            \n",
    "\n",
    "            for fl in range(2,len(self.files)):\n",
    "\n",
    "                data=pd.concat([data, pd.read_csv(self.files[fl],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None)])\n",
    "                \n",
    "        \n",
    "        # ===================Case for single file of light curve data==================================\n",
    "        except IndexError:\n",
    "            \n",
    "            \n",
    "            data = pd.read_csv(self.files[0],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None)\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        # ==================Magnitudes==================================\n",
    "        # ==============================================================\n",
    "        Id = data.iloc[:,self.data_dict['id']]\n",
    "        time = data.iloc[:,self.data_dict['time']]\n",
    "        \n",
    "        standard_data = {'ID':Id,'time':time}\n",
    "        \n",
    "        if 'mag' in self.data_dict.keys(): \n",
    "            \n",
    "            \n",
    "            # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            try:\n",
    "                \n",
    "                \n",
    "        \n",
    "                for i in range(len(self.data_dict['mag'])):\n",
    "                    \n",
    "                    \n",
    "                    # Separatting the columns as per input dictionary\n",
    "    #             \n",
    "\n",
    "                    # Case where there are brightness error columns\n",
    "                    if 'mag_err' in self.data_dict.keys():                \n",
    "\n",
    "                        # Creating a new dictionary for the columns above separate data\n",
    "                        standard_data.update({'mag'+str(i+1):data.iloc[:,self.data_dict['mag'][i]],\n",
    "                                              'mag_error'+str(i+1):data.iloc[:,self.data_dict['mag_err'][i]]})\n",
    "\n",
    "                    # Case were there are no error columns\n",
    "                    else:\n",
    "\n",
    "                        standard_data.update({'mag'+str(i+1):data.iloc[:,self.data_dict['mag'][i]]})\n",
    "                    \n",
    "                    \n",
    "            \n",
    "                \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "            except TypeError:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']]; \n",
    "                \n",
    "                if 'mag_err' in self.data_dict.keys():\n",
    "                    \n",
    "                    \n",
    "                    mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data.update({'mag':mag,'mag_error':mag_error})\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    standard_data.update({'mag':mag})\n",
    "                            \n",
    "            \n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            if 'filters'in self.data_dict.keys() and 'mag_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "                mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'mag':mag,'mag_error':mag_error,'filters':filters})\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'mag':mag,'filters':filters})\n",
    "                \n",
    "                \n",
    "                \n",
    "                    \n",
    "                    \n",
    "    #-----------------------------------------------------------------------------------------------------------------                \n",
    "                \n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````      \n",
    "    #============================================Fluxes===============================================================\n",
    "    #=================================================================================================================\n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            \n",
    "                    # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            try:\n",
    "                \n",
    "                \n",
    "        \n",
    "                for i in range(len(self.data_dict['flux'])):\n",
    "                    \n",
    "                    \n",
    "                    # Separatting the columns as per input dictionary\n",
    "    #             \n",
    "\n",
    "                    # Case where there are brightness error columns\n",
    "                    if 'flux_err' in self.data_dict.keys():                \n",
    "\n",
    "                        # Creating a new dictionary for the columns above separate data\n",
    "                        standard_data.update({'flux'+str(i+1):data.iloc[:,self.data_dict['flux'][i]],\n",
    "                                              'flux_error'+str(i+1):data.iloc[:,self.data_dict['flux_err'][i]]})\n",
    "                    # Case were there are no error columns\n",
    "                    else:\n",
    "\n",
    "                        standard_data.update({'flux'+str(i+1):data.iloc[:,self.data_dict['flux'][i]]})\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            except TypeError:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']]; \n",
    "\n",
    "                if 'flux_err' in self.data_dict.keys():\n",
    "\n",
    "\n",
    "                    flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data.update({'flux':flux,'flux_error':flux_error})\n",
    "\n",
    "                else:\n",
    "\n",
    "                    standard_data.update({'flux':flux})\n",
    "\n",
    "\n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            if 'filters'in self.data_dict.keys() and 'flux_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "                flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'flux':flux,'flux_error':flux_error,'filters':filters})\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'flux':flux,'filters':filters})\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "          \n",
    "            \n",
    "        ids = np.unique(standard_data['ID'])   \n",
    "        self.metadata = pd.DataFrame({'ID': ids}, index=ids)\n",
    "        self.light_curves_data = pd.DataFrame.from_dict(standard_data)\n",
    "    \n",
    "    def get_display_data(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single instance of the dataset in a form that is ready to be\n",
    "        displayed by the web front end.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : str\n",
    "            Index (should be a string to avoid ambiguity)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            json-compatible dictionary of the light curve data\n",
    "        \"\"\"\n",
    " \n",
    "\n",
    "\n",
    "        # All the standard columns are included here\n",
    "        data_col = ['mag','flux','mag1','mag2','flux1','flux2','filters']\n",
    "\n",
    "        err_col = ['mag_error','flux_error']\n",
    "\n",
    "        out_dict = {}\n",
    "\n",
    "\n",
    "            \n",
    "        # Reading in the light curve data\n",
    "\n",
    "        light_curve = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "\n",
    "        # Data and error index \n",
    "        mag_indx = [cl for cl in data_col if cl in light_curve.columns.values.tolist()] \n",
    "        err_indx = [cl for cl in err_col if cl in light_curve.columns.values.tolist()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Returns true if we have error columns\n",
    "        if err_col[0] in light_curve.columns.values.tolist() or err_col[1] in light_curve.columns.values.tolist():\n",
    "\n",
    "\n",
    "            light_curve['err_lower'] = light_curve[mag_indx].values - light_curve[err_indx].values\n",
    "            light_curve['err_upper'] = light_curve[mag_indx].values + light_curve[err_indx].values\n",
    "            lc_errs = light_curve[['time', 'err_lower', 'err_upper']]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # inserting the time column to data and adding 'data'\n",
    "        # and 'errors' to out_dict\n",
    "        mag_indx.insert(0,'time')\n",
    "        out_dict['data'] = light_curve[mag_indx].values.tolist()\n",
    "        out_dict['errors'] = lc_errs.values.tolist()\n",
    "\n",
    "        \n",
    "        return out_dict\n",
    "    \n",
    "\n",
    "    def get_sample(self,idx):\n",
    "        \n",
    "        \n",
    "        # All the standard columns for feature extraction \n",
    "        data_col = ['time','mag','flux','mag1','mag2','flux1','flux2','mag_error','flux_error']\n",
    "\n",
    "        \n",
    "\n",
    "        # empty pandas dataframe to update as per data_col\n",
    "        out_data = pd.DataFrame({})\n",
    "        try:\n",
    "\n",
    "            \n",
    "   \n",
    "            # Choosing light curve values for a specific ID\n",
    "            light_curve = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "            \n",
    "            \n",
    "            sample_data = []\n",
    "            # Getting the columns that correspond to lc columns \n",
    "            for cl in data_col:\n",
    "                \n",
    "                if cl in light_curve.columns.values.tolist():\n",
    "\n",
    "                    out_data[cl] = light_curve[cl].values.tolist()\n",
    "                    sample_data.append(out_data[cl])\n",
    "            \n",
    "                \n",
    "            \n",
    "        except (pd.errors.ParserError, pd.errors.EmptyDataError, FileNotFoundError) as e:\n",
    "            print('Error parsing file', flpath)\n",
    "            print('Error message:')\n",
    "            print(e)\n",
    "            out_dict = {'data': [], 'errors': []}\n",
    "            \n",
    "            \n",
    "            \n",
    "        return sample_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "# from astronomaly.base.base_dataset import Dataset\n",
    "\n",
    "\n",
    "class LightCurveDataset(object):\n",
    "    def __init__(self,data_dict,files,header_nrows=1,delim_whitespace =False,**kwargs):\n",
    "        \"\"\"\n",
    "        Reads in light curve data from file(s).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            If a single file (of any time) is to be read from, the path can be\n",
    "            given using this kwarg. \n",
    "        directory : str\n",
    "            A directory can be given instead of an explicit list of files. The\n",
    "            child class will load all appropriate files in this directory.\n",
    "        list_of_files : list\n",
    "            Instead of the above, a list of files to be loaded can be\n",
    "            explicitly given.\n",
    "        output_dir : str\n",
    "            The directory to save the log file and all outputs to. Defaults to\n",
    "            './' \n",
    "        \n",
    "        data_dict: Dictionary\n",
    "                It a dictionary with index of the column names corresponding to the \n",
    "                following specific keys: ('time','mag','mag_err','flux','flux_err','filters')\n",
    "                \n",
    "                e.g {'time':1,'mag':2}, were 1 and 2 are column index correpoding to \n",
    "                'time' and 'mag' in the input data .\n",
    "                \n",
    "                The user can also provide a list of indices for the 'mag' and 'flux' columns. This is the\n",
    "                case were the brightness is recorded in more than one column.\n",
    "                \n",
    "                e.g {'time':1,'mag':[2,3]} 2 and 3 corresponds to columns with brightness records\n",
    "        \n",
    "        header_nrows: int\n",
    "                The number of rows the header covers in the dataset, by \n",
    "                default 1\n",
    "                \n",
    "         delim_whitespace: bool\n",
    "                Should be True if the data is not separated by a comma, by\n",
    "                default False\n",
    "                \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "#         super().__init__(data_dict,header_nrows=1,delim_whitespace =False,**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "        self.data_type = 'light_curve'\n",
    "        self.metadata = pd.DataFrame(data=[])\n",
    "        \n",
    "\n",
    "        ##### need to understand this line of code!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # ids = [f.split(os.sep)[-1] for f in self.files]\n",
    "        # self.metadata = pd.DataFrame({'filepath': self.files}, index=ids)\n",
    "\n",
    "        \n",
    "\n",
    "        self.data_dict = data_dict\n",
    "        self.header_nrows = header_nrows\n",
    "        self.delim_whitespace = delim_whitespace\n",
    "        self.files = files\n",
    "     \n",
    "        \n",
    "#         ========================================================================================\n",
    "                                   \n",
    "                                    # Reading the light curve data \n",
    "        \n",
    "#         ========================================================================================\n",
    "\n",
    "#     @staticmethod\n",
    "#     def read_lc_from_file(self,flpath):\n",
    "\n",
    "        \n",
    "        '''Function to read the lc from the data\n",
    "        \n",
    "        Input:\n",
    "        flpath: the location of the file\n",
    "        \n",
    "    \n",
    "                \n",
    "        Output:\n",
    "       standardized pandas dataframe with lc data'''\n",
    "        \n",
    "        \n",
    "        # Reading-in the data\n",
    "        \n",
    "        \n",
    "        \n",
    "        # ===================Case for multiple files of light curve data================================\n",
    "        try:\n",
    "\n",
    "            data=pd.concat([pd.read_csv(self.files[0],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None),\n",
    "                               \n",
    "                               pd.read_csv(self.files[1],skiprows=self.header_nrows,\n",
    "                                           delim_whitespace=self.delim_whitespace,header=None)])\n",
    "            \n",
    "            \n",
    "\n",
    "            for fl in range(2,len(self.files)):\n",
    "\n",
    "                data=pd.concat([data, pd.read_csv(self.files[fl],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None)])\n",
    "                \n",
    "        \n",
    "        # ===================Case for single file of light curve data==================================\n",
    "        except IndexError:\n",
    "            \n",
    "            \n",
    "            data = pd.read_csv(self.files[0],skiprows=self.header_nrows,\n",
    "                               delim_whitespace=self.delim_whitespace,header=None)\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # ==================Magnitudes==================================\n",
    "        # ==============================================================\n",
    "        ID = data.iloc[:,self.data_dict['id']]\n",
    "        time = data.iloc[:,self.data_dict['time']]\n",
    "        \n",
    "        standard_data = {'ID':ID,'time':time}\n",
    "        if 'mag' in self.data_dict.keys(): \n",
    "            \n",
    "            \n",
    "            # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            try:\n",
    "                \n",
    "                \n",
    "        \n",
    "                for i in range(len(self.data_dict['mag'])):\n",
    "                    \n",
    "                    \n",
    "                    # Separatting the columns as per input dictionary\n",
    "    #             \n",
    "\n",
    "                    # Case where there are brightness error columns\n",
    "                    if 'mag_err' in self.data_dict.keys():                \n",
    "\n",
    "\n",
    "                        # Creating a new dictionary for the columns above separate data\n",
    "                        standard_data.update({'mag'+str(i+1):data.iloc[:,self.data_dict['mag'][i]],\n",
    "                                              'mag_error'+str(i+1):data.iloc[:,self.data_dict['mag_err'][i]]})\n",
    "                    # Case were there are no error columns\n",
    "                    else:\n",
    "\n",
    "                        standard_data.update({'mag'+str(i+1):data.iloc[:,self.data_dict['mag'][i]]})\n",
    "                    \n",
    "                    \n",
    "            \n",
    "                \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "            except TypeError:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']]; \n",
    "                \n",
    "                if 'mag_err' in self.data_dict.keys():\n",
    "                    \n",
    "                    \n",
    "                    mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "                    # Updating the 'standard' dictionary for the columns above separate data\n",
    "                    standard_data.update({'mag':mag,'mag_error':mag_error})\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    standard_data.update({'mag':mag})\n",
    "                            \n",
    "            \n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            if 'filters'in self.data_dict.keys() and 'mag_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "                mag_error = data.iloc[:,self.data_dict['mag_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'mag':mag,'mag_error':mag_error,'filters':filters})\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; mag = data.iloc[:,self.data_dict['mag']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'mag':mag,'filters':filters})\n",
    "                \n",
    "                \n",
    "                \n",
    "                    \n",
    "                    \n",
    "    #-----------------------------------------------------------------------------------------------------------------                \n",
    "                \n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````      \n",
    "    #============================================Fluxes===============================================================\n",
    "    #=================================================================================================================\n",
    "    #`````````````````````````````````````````````````````````````````````````````````````````````````````````````````\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            \n",
    "                    # ============MUtliple Mag columns=========================\n",
    "            \n",
    "            # The case of multiple brightness columns        \n",
    "            try:\n",
    "                \n",
    "                \n",
    "        \n",
    "                for i in range(len(self.data_dict['flux'])):\n",
    "                    \n",
    "                    \n",
    "                    # Separatting the columns as per input dictionary\n",
    "    #             \n",
    "\n",
    "                    # Case were there are brightness error columns\n",
    "                    if 'flux_err' in self.data_dict.keys():                \n",
    "\n",
    "                        flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "                        # Creating a new dictionary for the columns above separate data\n",
    "                        standard_data.update({'flux'+str(i+1):data.iloc[:,self.data_dict['flux'][i]],\n",
    "                                              'flux_error'+str(i+1):data.iloc[:,self.data_dict['flux_err'][i]]})\n",
    "                    # Case were there are no error columns\n",
    "                    else:\n",
    "\n",
    "                        standard_data.update({'flux'+str(i+1):data.iloc[:,self.data_dict['flux'][i]]})\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            except TypeError:    \n",
    "                \n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']]; \n",
    "\n",
    "                if 'flux_err' in self.data_dict.keys():\n",
    "\n",
    "\n",
    "                    flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "                    # Creating a new dictionary for the columns above separate data\n",
    "                    standard_data.update({'flux':flux,'flux_error':flux_error})\n",
    "\n",
    "                else:\n",
    "\n",
    "                    standard_data.update({'flux':flux})\n",
    "\n",
    "\n",
    "            \n",
    "                    \n",
    "            # ============Column with Mag_filters and errors==========================\n",
    "            \n",
    "            # Including filters in dataframe\n",
    "            if 'filters'in self.data_dict.keys() and 'flux_err' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "                flux_error = data.iloc[:,self.data_dict['flux_err']]\n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'flux':flux,'flux_error':flux_error,'filters':filters})\n",
    "                \n",
    "            elif 'filters' in self.data_dict.keys():\n",
    "                \n",
    "                # Separatting the columns as per input dictionary\n",
    "                time = data.iloc[:,self.data_dict['time']]; flux = data.iloc[:,self.data_dict['flux']];\n",
    "        \n",
    "\n",
    "                filters = data.iloc[:,self.data_dict['filters']]\n",
    "                standard_data.update({'flux':flux,'filters':filters})\n",
    "                \n",
    "                \n",
    "                   \n",
    "            #=================Single Mag Column with and with errors============================\n",
    "            \n",
    "            # Case of single brightness columns    \n",
    "              \n",
    "        ids = np.unique(standard_data['ID'])   \n",
    "        self.metadata = pd.DataFrame({'ID': ids}, index=ids)\n",
    "        self.light_curves_data = pd.DataFrame.from_dict(standard_data)\n",
    "        \n",
    "    \n",
    "    def get_display_data(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single instance of the dataset in a form that is ready to be\n",
    "        displayed by the web front end.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : str\n",
    "            Index (should be a string to avoid ambiguity)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            json-compatible dictionary of the light curve data\n",
    "        \"\"\"\n",
    " \n",
    "\n",
    "\n",
    "        # All the standard columns are included here\n",
    "        data_col = ['mag','flux','mag1','mag2','flux1','flux2','filters']\n",
    "\n",
    "        err_col = ['mag_error','flux_error']\n",
    "\n",
    "        out_dict = {}\n",
    "\n",
    "\n",
    "            \n",
    "        # Reading in the light curve data\n",
    "\n",
    "        light_curve = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "\n",
    "        # Data and error index \n",
    "        mag_indx = [cl for cl in data_col if cl in light_curve.columns.values.tolist()] \n",
    "        err_indx = [cl for cl in err_col if cl in light_curve.columns.values.tolist()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Returns true if we have error columns\n",
    "        if err_col[0] in light_curve.columns.values.tolist() or err_col[1] in light_curve.columns.values.tolist():\n",
    "\n",
    "\n",
    "            light_curve['err_lower'] = light_curve[mag_indx].values - light_curve[err_indx].values\n",
    "            light_curve['err_upper'] = light_curve[mag_indx].values + light_curve[err_indx].values\n",
    "            lc_errs = light_curve[['time', 'err_lower', 'err_upper']]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # inserting the time column to data and adding 'data'\n",
    "        # and 'errors' to out_dict\n",
    "        mag_indx.insert(0,'time')\n",
    "        out_dict['data'] = light_curve[mag_indx].values.tolist()\n",
    "        out_dict['errors'] = lc_errs.values.tolist()\n",
    "\n",
    "            \n",
    "\n",
    "        return out_dict\n",
    "    \n",
    "\n",
    "    def get_sample(self,idx):\n",
    "        \n",
    "        \n",
    "        # All the standard columns for feature extraction \n",
    "        data_col = ['time','mag','flux','mag1','mag2','flux1','flux2','mag_error','flux_error']\n",
    "\n",
    "        \n",
    "\n",
    "        # empty pandas dataframe to update as per data_col\n",
    "        out_data = pd.DataFrame({})\n",
    "        try:\n",
    "\n",
    "            \n",
    "   \n",
    "            # Choosing light curve values for a specific ID\n",
    "            light_curve = self.light_curves_data[self.light_curves_data['ID']==idx]\n",
    "            \n",
    "            \n",
    "            sample_data = []\n",
    "            # Getting the columns that correspond to lc columns \n",
    "            for cl in data_col:\n",
    "                \n",
    "                if cl in light_curve.columns.values.tolist():\n",
    "\n",
    "                    out_data[cl] = light_curve[cl].values.tolist()\n",
    "                    sample_data.append(out_data[cl])\n",
    "            \n",
    "                \n",
    "            \n",
    "        except (pd.errors.ParserError, pd.errors.EmptyDataError, FileNotFoundError) as e:\n",
    "            print('Error parsing file', flpath)\n",
    "            print('Error message:')\n",
    "            print(e)\n",
    "            out_dict = {'data': [], 'errors': []}\n",
    "            \n",
    "            \n",
    "            \n",
    "        return sample_data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flux']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-86-7bbfe1e7048b>:352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  light_curve['err_lower'] = light_curve[mag_indx].values - light_curve[err_indx].values\n",
      "<ipython-input-86-7bbfe1e7048b>:353: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  light_curve['err_upper'] = light_curve[mag_indx].values + light_curve[err_indx].values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>time</th>\n",
       "      <th>flux</th>\n",
       "      <th>flux_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>59798.3205</td>\n",
       "      <td>-1.299735</td>\n",
       "      <td>1.357315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>59798.3281</td>\n",
       "      <td>-2.095392</td>\n",
       "      <td>1.148654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>59798.3357</td>\n",
       "      <td>-0.923794</td>\n",
       "      <td>1.763655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>59798.3466</td>\n",
       "      <td>-4.009815</td>\n",
       "      <td>2.602911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>59798.3576</td>\n",
       "      <td>-3.403503</td>\n",
       "      <td>5.367328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855953</th>\n",
       "      <td>342868</td>\n",
       "      <td>60434.0005</td>\n",
       "      <td>13.435188</td>\n",
       "      <td>1.301140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855954</th>\n",
       "      <td>342868</td>\n",
       "      <td>60434.0115</td>\n",
       "      <td>11.484802</td>\n",
       "      <td>1.979236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855955</th>\n",
       "      <td>342868</td>\n",
       "      <td>60434.0224</td>\n",
       "      <td>13.092712</td>\n",
       "      <td>4.928932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855956</th>\n",
       "      <td>342868</td>\n",
       "      <td>60435.9857</td>\n",
       "      <td>2.289347</td>\n",
       "      <td>2.553590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855957</th>\n",
       "      <td>342868</td>\n",
       "      <td>60436.9840</td>\n",
       "      <td>-0.469974</td>\n",
       "      <td>2.922369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10855958 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID        time       flux  flux_error\n",
       "0             13  59798.3205  -1.299735    1.357315\n",
       "1             13  59798.3281  -2.095392    1.148654\n",
       "2             13  59798.3357  -0.923794    1.763655\n",
       "3             13  59798.3466  -4.009815    2.602911\n",
       "4             13  59798.3576  -3.403503    5.367328\n",
       "...          ...         ...        ...         ...\n",
       "10855953  342868  60434.0005  13.435188    1.301140\n",
       "10855954  342868  60434.0115  11.484802    1.979236\n",
       "10855955  342868  60434.0224  13.092712    4.928932\n",
       "10855956  342868  60435.9857   2.289347    2.553590\n",
       "10855957  342868  60436.9840  -0.469974    2.922369\n",
       "\n",
       "[10855958 rows x 4 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2 = ['/home/malema/Desktop/Malema_UWC_Work/Data/test_set_batch1.csv']\n",
    "         \n",
    "#          ,'/home/malema/Desktop/Malema_UWC_Work/Data/test_set_batch1.csv']\n",
    "\n",
    "md = LightCurveDataset(data_dict={'time':1,'flux':3,'flux_err':4,'id':0,'fliters':2},files=path2,\n",
    "                     delim_whitespace=False,header_nrows=1)\n",
    "\n",
    "\n",
    "\n",
    "dsp = md.get_display_data(idx=14)\n",
    " \n",
    "# lc[lc['Id']==40]\n",
    "\n",
    "z = md.light_curves_data\n",
    "\n",
    "ls = ['mag']\n",
    "ls.insert(0,'time')\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f87b129c9a0>]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.array(dsp['data'])[:,0],np.array(dsp['data'])[:,1],'.')\n",
    "\n",
    "# np.array(dsp['data'])[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = md.light_curves_data[['mag']].values - md.light_curves_data[['ID']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time', 'mag_error', 'flux_error']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "err_col = ['mag_error','flux_error']\n",
    "\n",
    "err_indx = [cl for cl in err_col if cl in z.columns.values.tolist()]\n",
    "\n",
    "err_indx.append('time')\n",
    "\n",
    "err_col.insert(0,'time')\n",
    "\n",
    "# err_indx\n",
    "\n",
    "err_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing if get_sample works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malema/anaconda3/lib/python3.8/site-packages/feets/extractors/core.py:234: ExtractorWarning: The original FATS documentation says that the result of AndersonDarling must be ~0.25 for gausian distribution but the  result is ~-0.60\n",
      "  warnings.warn(w, ExtractorWarning)\n"
     ]
    },
    {
     "ename": "DataRequiredError",
     "evalue": "magnitude",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataRequiredError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bb6cac4902c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdsp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/feets/core.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, time, magnitude, error, magnitude2, aligned_time, aligned_magnitude, aligned_magnitude2, aligned_error, aligned_error2)\u001b[0m\n\u001b[1;32m    277\u001b[0m                 aligned_error=None, aligned_error2=None):\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         kwargs = self.dict_data_as_array({\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0mDATA_TIME\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mDATA_MAGNITUDE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/feets/core.py\u001b[0m in \u001b[0;36mdict_data_as_array\u001b[0;34m(self, d)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_required_data\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mDataRequiredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0marray_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marray_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataRequiredError\u001b[0m: magnitude"
     ]
    }
   ],
   "source": [
    "import feets\n",
    "\n",
    "# The features from the light curves\n",
    "fs = feets.FeatureSpace(\n",
    "\n",
    "    only=['StructureFunction_index_21','Mean','AndersonDarling','Amplitude','Freq1_harmonics_rel_phase_1',\n",
    "          'MaxSlope','LinearTrend','Beyond1Std','CAR_sigma','Period_fit','SlottedA_length',\n",
    "          'SmallKurtosis','Autocor_length','Con','Eta_e'] ) \n",
    "\n",
    "lc = dsp\n",
    "features, values = fs.extract(*lc)\n",
    "val = values.tolist()\n",
    "\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [1,2,3,50]\n",
    "metadata = pd.DataFrame({'filepath': files}, index=[20,2,3,50])\n",
    "flpath = metadata['filepath'].iloc[3]\n",
    "# metadata.keys()\n",
    "\n",
    "flpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.iloc[0].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metadata)\n",
    "\n",
    "dt = pd.read_csv(path2)\n",
    "\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt1 = pd.DataFrame({'time':dt.mjd,'flux':dt.flux, 'flux_err':dt.flux_err }, index=dt.object_id.values)\n",
    "\n",
    "dt1 = {'time':[1,2], 'mag':[2,4]}\n",
    "dt2 = {'time':[1,2], 'mag':[1,2]}\n",
    "dt3 = {'time':[2,3], 'mag':[2,3]}\n",
    "dt4 = {'time':[0,0], 'mag':[0,0]}\n",
    "# dt3 = {'time':[2,3], 'mag':[2,3]}\n",
    "\n",
    "\n",
    "dt1 = pd.DataFrame(dt1);dt2 = pd.DataFrame(dt2); dt3 = pd.DataFrame(dt3);dt4 = pd.DataFrame(dt4)\n",
    "\n",
    "# print(dt1)\n",
    "# print(dt2)\n",
    "# print(dt3)\n",
    "\n",
    "lst = [dt1,dt2]\n",
    "try:\n",
    "\n",
    "    new_dat=pd.concat([lst[0],lst[1]])\n",
    "\n",
    "    for i in range(2,len(lst)):\n",
    "\n",
    "        new_dat=pd.concat([new_dat,lst[i]])\n",
    "        \n",
    "except IndexError:\n",
    "    \n",
    "    new_dat = lst[0]\n",
    "\n",
    "new_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1.loc[13,'time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0,1,50)\n",
    "\n",
    "y = np.sin(x)\n",
    "\n",
    "\n",
    "plt.plot(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrition = {'food':['mango','banana','pap','eggs'],'kcal':[10,30,80,100],'kJ':np.array([90,30,10,5])}\n",
    " \n",
    "nutrition['kJ'] = nutrition['kJ'] + 10\n",
    "\n",
    "nutrition = pd.DataFrame.from_dict(nutrition)\n",
    "\n",
    "nutrition\n",
    "\n",
    "for kj in nutrition['food']:\n",
    "    \n",
    "    print(kj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(nutrition.kcal,nutrition.kJ,'*r')\n",
    "plt.xlabel('kcal')\n",
    "plt.ylabel('kJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictn = {}\n",
    "dictn1 = {}\n",
    "\n",
    "fl1 = [1,2,3]\n",
    "fl2 = [4,6,1]\n",
    "fl3 = [20,4,5]\n",
    "fl4 = [0,0,0]\n",
    "\n",
    "dct = {'fl3':fl4}\n",
    "# dct = pd.DataFrame.from_dict(dct)\n",
    "\n",
    "\n",
    "files = [fl1,fl2,fl3]\n",
    "files2 = [fl1,fl2,fl3]\n",
    "\n",
    "for fls in range(len(files)):\n",
    "    \n",
    "    dictn['fl'+str(fls)] = files[fls]\n",
    "\n",
    "dt = pd.DataFrame.from_dict(dictn)\n",
    "    \n",
    "for fls in range(len(files2)):\n",
    "    \n",
    "    dictn1['fl'+str(fls)] = files2[fls]\n",
    "    \n",
    "dt1 = pd.DataFrame.from_dict(dictn1) \n",
    "\n",
    "dt1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'malema'+'brigdet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([dt,dt1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dct['dt','ft','gt'] = [1,1,1],[2,2,2],[3,3,3]\n",
    "\n",
    "dictn = {}\n",
    "dct = {'fl3':fl4}\n",
    "\n",
    "\n",
    "dct.update({'dt':[1,1,1],'ft':[2,2,2],'gt':[3,3,3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3])\n",
    "\n",
    "\n",
    "for i in range(len(x)):\n",
    "    \n",
    "    x[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_columns = [1,2,3]\n",
    "\n",
    "mags = {}\n",
    "\n",
    "cl = np.zeros(len(mag_columns))\n",
    "\n",
    "for i in range(len(mag_columns)):\n",
    "    \n",
    "#     cl[i] = mag_columns[i]\n",
    "    \n",
    "    mags['mag'+str(i)] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
