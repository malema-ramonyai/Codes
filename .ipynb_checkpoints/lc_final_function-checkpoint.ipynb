{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think the best is to use the column indexs\n",
    "def read_lc3(flpath,data_dict,header_nrows,delim_whitespace):\n",
    "    \n",
    "    '''Function to read the lc from the data\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    flpath: the location of the file\n",
    "    \n",
    "    data_dict: dictionary with the keys ('time','mag','mag_err','flux','flux_err','filters')\n",
    "               the user provides the values corresponding to the keys\n",
    "               e.g {'time':1}, were 1 is the time column index\n",
    "               \n",
    "    brightness_unit: Units used to measure the brightness\n",
    "                     can either be 'flux' or 'mags'\n",
    "                     \n",
    "    header_nrows: The number of rows the header covers\n",
    "    \n",
    "    delim_whitespace: True when the data is not separated by a comma, false otherwise\n",
    "               \n",
    "   Output:\n",
    "   \n",
    "   standardized pandas dataframe with lc data'''\n",
    "    \n",
    "    \n",
    "    # Reading-in the data\n",
    "    data = pd.read_csv(flpath,skiprows=header_nrows,delim_whitespace=delim_whitespace,header=None)\n",
    "    \n",
    "    \n",
    "    # ==================Magnitudes==================================\n",
    "    # ==============================================================\n",
    "    ID = data.iloc[:,data_dict['id']]\n",
    "    if 'mag' in data_dict.keys(): \n",
    "        \n",
    "        \n",
    "        # ============MUtliple Mag columns=========================\n",
    "        \n",
    "        # The case of multiple brightness columns        \n",
    "        if type(data_dict['mag']) == list:\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; mag1 = data.iloc[:,data_dict['mag'][0]];\n",
    "            mag2 = data.iloc[:,data_dict['mag'][1]]\n",
    "            \n",
    "            # Case where there are brightness error columns\n",
    "            if 'mag_err' in data_dict.keys():                \n",
    "                \n",
    "                mag_error = data.iloc[:,data_dict['mag_err']]\n",
    "                # Creating a new dictionary for the columns above separate data\n",
    "                standard_data = {'ID':ID,'time':time,'mag1':mag1,'mag2':mag2,'mag_error':mag_error}\n",
    "                \n",
    "            # Case were there are no error columns\n",
    "            else:\n",
    "                \n",
    "                standard_data = {'ID':ID,'time':time,'mag1':mag1,'mag2':mag2}\n",
    "                           \n",
    "        \n",
    "        \n",
    "                \n",
    "        # ============Column with Mag_filters and errors==========================\n",
    "        \n",
    "        # Including filters in dataframe\n",
    "        elif 'filters'in data_dict.keys() and 'mag_err' in data_dict.keys():\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; mag = data.iloc[:,data_dict['mag']];\n",
    "            mag_error = data.iloc[:,data_dict['mag_err']]\n",
    "\n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'ID':ID,'time':time,'mag':mag,'mag_error':mag_error,'filters':filters}\n",
    "            \n",
    "        elif 'filters' in data_dict.keys():\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; mag = data.iloc[:,data_dict['mag']];\n",
    "    \n",
    "\n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'ID':ID,'time':time,'mag':mag,'filters':filters}\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        #=================Single Mag Column with and with errors============================\n",
    "        \n",
    "        # Case of single brightness columns    \n",
    "        else:    \n",
    "            \n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; mag = data.iloc[:,data_dict['mag']]; \n",
    "            \n",
    "            if 'mag_err' in data_dict.keys():\n",
    "                \n",
    "                \n",
    "                mag_error = data.iloc[:,data_dict['mag_err']]\n",
    "                # Creating a new dictionary for the columns above separate data\n",
    "                standard_data = {'ID':ID,'time':time,'mag':mag,'mag_error':mag_error}\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                standard_data = {'ID':ID,'time':time,'mag':mag}\n",
    "                \n",
    "                \n",
    "#-----------------------------------------------------------------------------------------------------------------                \n",
    "            \n",
    "#`````````````````````````````````````````````````````````````````````````````````````````````````````````````````      \n",
    "#============================================Fluxes===============================================================\n",
    "#=================================================================================================================\n",
    "#`````````````````````````````````````````````````````````````````````````````````````````````````````````````````\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        \n",
    "        \n",
    "                # ============MUtliple Mag columns=========================\n",
    "        \n",
    "        # The case of multiple brightness columns        \n",
    "        if type(data_dict['flux']) == list:\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; flux1 = data.iloc[:,data_dict['flux'][0]];\n",
    "            flux2 = data.iloc[:,data_dict['flux'][1]]\n",
    "            \n",
    "            # Case where there are brightness error columns\n",
    "            if 'flux_err' in data_dict.keys():                \n",
    "                \n",
    "                flux_error = data.iloc[:,data_dict['flux_err']]\n",
    "                # Creating a new dictionary for the columns above separate data\n",
    "                standard_data = {'ID':ID,'time':time,'flux1':flux1,'flux2':flux2,'flux_error':flux_error}\n",
    "                \n",
    "            # Case were there are no error columns\n",
    "            else:\n",
    "                \n",
    "                standard_data = {'ID':ID,'time':time,'flux1':flux1,'flux2':flux2}\n",
    "                           \n",
    "        \n",
    "        \n",
    "                \n",
    "        # ============Column with Mag_filters and errors==========================\n",
    "        \n",
    "        # Including filters in dataframe\n",
    "        elif 'filters'in data_dict.keys() and 'flux_err' in data_dict.keys():\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; flux = data.iloc[:,data_dict['flux']];\n",
    "            flux_error = data.iloc[:,data_dict['flux_err']]\n",
    "\n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'ID':ID,'time':time,'flux':flux,'flux_error':flux_error,'filters':filters}\n",
    "            \n",
    "        elif 'filters' in data_dict.keys():\n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; flux = data.iloc[:,data_dict['flux']];\n",
    "    \n",
    "\n",
    "            filters = data.iloc[:,data_dict['filters']]\n",
    "            standard_data = {'ID':ID,'time':time,'flux':flux,'filters':filters}\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        #=================Single Mag Column with and with errors============================\n",
    "        \n",
    "        # Case of single brightness columns    \n",
    "        else:    \n",
    "            \n",
    "            \n",
    "            # Separatting the columns as per input dictionary\n",
    "            time = data.iloc[:,data_dict['time']]; flux = data.iloc[:,data_dict['flux']]; \n",
    "            \n",
    "            if 'flux_err' in data_dict.keys():\n",
    "                \n",
    "                \n",
    "                flux_error = data.iloc[:,data_dict['flux_err']]\n",
    "                # Creating a new dictionary for the columns above separate data\n",
    "                standard_data = {'ID':ID,'time':time,'flux':flux,'flux_error':flux_error}\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                standard_data = {'ID':ID,'time':time,'flux':flux}\n",
    "        \n",
    "        \n",
    "    \n",
    "    return pd.DataFrame.from_dict(standard_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the function on three available files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/MachineLearningUniandes/MANTRA/master/data/lightcurves/transient_lightcurves.csv\"\n",
    "url1 = 'https://raw.githubusercontent.com/MachineLearningUniandes/MANTRA/master/data/lightcurves/transient_labels.csv'\n",
    "url2 = 'https://raw.githubusercontent.com/MachineLearningUniandes/MANTRA/master/data/lightcurves/transient_info.txt'\n",
    "# transient_lc = pd.read_csv(url)\n",
    "\n",
    "path1 = '/home/malema/Desktop/Malema_UWC_Work/Data/20121012_02331333_O_CrabNebula_E.dat' # Oseti\n",
    "path2 = '/home/malema/Desktop/Malema_UWC_Work/Data/test_set_batch1.csv'  # Plastic\n",
    "path3 = url  # CRTS\n",
    "\n",
    "oSETI_dt=read_lc3(flpath=path1,data_dict={'time':1,'flux':[2,3],'id':5},delim_whitespace=True,header_nrows=2)\n",
    "\n",
    "plasticc_dt=read_lc3(flpath=path2,data_dict={'time':1,'flux':3,'flux_err':4,'id':0,'filters':2},\n",
    "                     delim_whitespace=False,header_nrows=1)\n",
    "\n",
    "CRTS_dt=read_lc3(flpath=path3,data_dict={'time':4,'mag':2,'mag_err':3,'id':0},\n",
    "                     delim_whitespace=False,header_nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRTS \n",
      "                           ID          time      mag  mag_error\n",
      "0  TranID1409030010044114444  53766.089871  18.8765   0.166417\n",
      "1  TranID1409030010044114444  53990.458866  20.0519   0.281733\n",
      "2  TranID1409030010044114444  53996.286004  20.2199   0.295764\n",
      "3  TranID1409030010044114444  54385.205789  21.1192   0.495390\n",
      "4  TranID1409030010044114444  54355.282285  19.3289   0.195002 \n",
      "\n",
      "oSETI \n",
      "      ID      time     flux1     flux2\n",
      "0  8607  0.106574  0.000082 -0.102021\n",
      "1  8608  0.106574  0.000017 -0.108044\n",
      "2  8609  0.106574  0.000017 -0.094419\n",
      "3  8610  0.106574  0.000050 -0.101473\n",
      "4  8611  0.106574  0.000050 -0.103084 \n",
      "\n",
      "Plastc \n",
      "    ID        time      flux  flux_error  filters\n",
      "0  13  59798.3205 -1.299735    1.357315        2\n",
      "1  13  59798.3281 -2.095392    1.148654        1\n",
      "2  13  59798.3357 -0.923794    1.763655        3\n",
      "3  13  59798.3466 -4.009815    2.602911        4\n",
      "4  13  59798.3576 -3.403503    5.367328        5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('CRTS \\n',CRTS_dt.head(),'\\n')\n",
    "\n",
    "print('oSETI \\n',oSETI_dt.head(),'\\n')\n",
    "print('Plastc \\n',plasticc_dt.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
